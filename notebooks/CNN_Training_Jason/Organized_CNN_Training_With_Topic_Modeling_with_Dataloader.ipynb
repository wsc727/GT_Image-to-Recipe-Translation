{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Organized_CNN_Training_With_Topic_Modeling_with_Dataloader.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ulkqg44lPcVP"
      },
      "source": [
        "## Conduct the CNN model training based on the im2recipe image dataset and the topic modeling(NMF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXIAqoeb1VIR"
      },
      "source": [
        "## Import 1.Module  2.Layer1&Layer2 json  3.Create title cleaned validation & test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvG8xCqQ1ZUd",
        "outputId": "fd4e5100-5db6-478f-ba66-c6192bb3e6b2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import os, csv\n",
        "import json  \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import gensim.corpora as corpora\n",
        "from operator import itemgetter\n",
        "import operator\n",
        "import pickle\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader \n",
        "import time\n",
        "import copy\n",
        "import torch.nn.functional as F\n",
        "os.chdir(\"/content/gdrive/My Drive/2021 Summer CS7643 Share Folder/data/recipe1M\")\n",
        "layer1 = json.load(open(\"layer1.json\", \"r\"))\n",
        "layer2 = json.load(open(\"layer2.json\", \"r\"))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTYWtAhf_UTM"
      },
      "source": [
        "# create title cleaned dataframe for val/test dataset, please enter true or false\n",
        "create_val_df = True\n",
        "create_test_df = True\n",
        "create_train_df = False\n",
        "\n",
        "# No need to enter, just to store dataframe in case we need it for visualization\n",
        "df_title_val = None # dataframe with cleaned title for validation dataset\n",
        "df_title_test = None # dataframe with cleaned title for test dataset\n",
        "df_title_traing = None # dataframe with cleaned title for test dataset\n",
        "\n",
        "\n",
        "# ======== No need to modify code below ============================================\n",
        "# function to create the cleaned title dataframe work\n",
        "def create_clean_titled_df(data_type): # datatype should be either \"val\" or \"test\"\n",
        "  layer1_data_list = []\n",
        "  for i in range(len(layer1)):\n",
        "    temp = {}\n",
        "    if layer1[i][\"partition\"] == data_type:\n",
        "      temp[\"id\"] = layer1[i][\"id\"]\n",
        "      temp['title'] = layer1[i]['title']\n",
        "      layer1_data_list.append(temp)\n",
        "  df_title = pd.DataFrame(layer1_data_list)\n",
        "  # Remove everything that is not alphanumeric or underscore\n",
        "  df_title['title_clean'] = df_title['title'].apply(lambda x: re.sub(r'[^\\w]', ' ', x))\n",
        "  # Convert the titles to lowercase\n",
        "  df_title['title_clean'] = df_title['title_clean'].apply(lambda x: x.lower())\n",
        "  return df_title\n",
        "\n",
        "if create_val_df:\n",
        "  df_title_val = create_clean_titled_df(\"val\")\n",
        "  df_title_val.to_csv(\"layer1_title_val.csv\")\n",
        "if create_test_df:\n",
        "  df_title_test = create_clean_titled_df(\"test\")\n",
        "  df_title_test.to_csv(\"layer1_title_test.csv\")\n",
        "if create_train_df:\n",
        "  df_title_train = create_clean_titled_df(\"train\")\n",
        "  df_title_train.to_csv(\"layer1_title_train.csv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Sjg61q4Zbwq",
        "outputId": "20dd9cc1-e8db-4ed9-f50d-a0ae1ff38a97"
      },
      "source": [
        "print(df_title_val)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                id  ...                                title_clean\n",
            "0       00011e0b2c  ...                    steak   asparagus wraps\n",
            "1       00011fc1f9  ...                     lentils vegetable soup\n",
            "2       000128a538  ...                            harrison muesli\n",
            "3       00025af750  ...   spanish spiked gazpacho in cucumber cups\n",
            "4       00029df38f  ...                             praline kisses\n",
            "...            ...  ...                                        ...\n",
            "155031  fffe6545e6  ...  baked pasta with sausage and tomato pesto\n",
            "155032  fffe89ea7e  ...                    fennel prawn conchiglie\n",
            "155033  fffebe68b3  ...                        easy fattoush salad\n",
            "155034  ffff03a753  ...                      kidney beans and corn\n",
            "155035  ffffbb45d2  ...           baumkuchen    the king of cakes \n",
            "\n",
            "[155036 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_yUQHwbUwjd"
      },
      "source": [
        "## Apply topic modeling on val/test dataset for categorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kODVfFzvDs-Z"
      },
      "source": [
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        # deacc=True removes punctuations\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
        "def remove_stopwords(texts):\n",
        "    return [[word.strip() for word in simple_preprocess(str(doc)) \n",
        "             if word.strip() not in stop_words] for doc in texts]\n",
        "def get_top_cat_for_recipe(recipes_all_list, w_vector):\n",
        "    final_recipes_cat_name = []\n",
        "    recipe_cat_link = []\n",
        "    for r in range(len(recipes_all_list)):\n",
        "        one_hot_matrix = w_vector[r,:]\n",
        "        all_zeros = not one_hot_matrix.any() # no fitting category\n",
        "        if all_zeros: recipe_cat_link.append(-1) # no fitting category\n",
        "        else:\n",
        "            top_indic = np.argsort(one_hot_matrix)[::-1][0] # 1. umdrehen 2. return erste\n",
        "            recipe_cat_link.append(top_indic)\n",
        "    for num in recipe_cat_link:\n",
        "        if num == -1: final_recipes_cat_name.append('no_cat')\n",
        "        else: final_recipes_cat_name.append(topics_category_300[num])\n",
        "    return final_recipes_cat_name\n",
        "def topic_ext (list_dic):\n",
        "  new_list = []\n",
        "  for i in list_dic:\n",
        "    if i == \"no_cat\":\n",
        "      new_list.append(i)\n",
        "    else:\n",
        "      new_list.append(i['topic'])\n",
        "  return new_list"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhZFriZX37oW",
        "outputId": "dc74e2cc-9a08-4b77-987f-4e4d371b9555"
      },
      "source": [
        "# build the nmf model for topic categorization\n",
        "training_data = \"val\" # argument: \"val\", \"test\", \"train\"\n",
        "testing_data = \"test\" # argument: \"val\", \"test\", \"train\"\n",
        "training_df = None # to be assigned based on the training_data argument\n",
        "testing_df = None # to be assigned based on the testing_data argument\n",
        "\n",
        "n_topics = 300 # number of topics\n",
        "nmf_model = None # built NMF model, no need to enter\n",
        "\n",
        "nmf_training_set_topic = None # topic for each row in training set\n",
        "nmf_testing_set_topic = None # topic for each row in testing set\n",
        "\n",
        "# ======== No need to modify code below ======================================================\n",
        "# get the corresponding topic for trainig and testing dataset\n",
        "if training_data == \"val\":\n",
        "  training_df = df_title_val\n",
        "elif training_data == \"train\":\n",
        "  training_df = df_title_traing\n",
        "elif training_data == \"test\":\n",
        "  training_df = df_title_test\n",
        "if testing_data == \"val\":\n",
        "  testing_df = df_title_val\n",
        "elif testing_data == \"train\":\n",
        "  testing_df = df_title_traing\n",
        "elif testing_data == \"test\":\n",
        "  testing_df = df_title_test\n",
        "\n",
        "# creating files for training and validation\n",
        "df_title_val = pd.read_csv(\"layer1_title_val.csv\")\n",
        "df_title_test = pd.read_csv(\"layer1_title_test.csv\")\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'with', 'and', 'recipe', 'in', 'a', 's'])\n",
        "data = training_df[\"title_clean\"].values.tolist()\n",
        "data_words = list(sent_to_words(data))\n",
        "data_words = remove_stopwords(data_words)\n",
        "data_test = testing_df[\"title_clean\"].values.tolist()\n",
        "data_words_test = list(sent_to_words(data_test))\n",
        "data_words_test = remove_stopwords(data_words_test)\n",
        "# building nmf model\n",
        "data_samples = [' '.join(item) for item in data_words]\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.99, max_features=None)\n",
        "tfidf = tfidf_vectorizer.fit_transform(data_samples) #tfidf.shape #(144128, 21930)\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
        "pickle.dump(tfidf_vectorizer, open(\"vectorizer_nmf_07262021.pickle\", \"wb\")) #Save vectorizer\n",
        "nmf_300 = NMF(n_components=n_topics, random_state=1, alpha=.1, l1_ratio=.5, verbose=2, max_iter=5).fit(tfidf)\n",
        "nmf_embedding = nmf_300.transform(tfidf) #W matitx \n",
        "# get topcis\n",
        "top_idx = np.argsort(nmf_embedding,axis=0)[-1:]\n",
        "show_300 = 300\n",
        "count_idxs = 0\n",
        "final_names = data_words\n",
        "topics_category_300 = []\n",
        "for idxs in top_idx.T:\n",
        "    if count_idxs == show_300: break\n",
        "    for idx in idxs:\n",
        "      temp = {}\n",
        "      temp[\"topic_idx\"] = count_idxs\n",
        "      temp[\"topic\"] = final_names[idx]\n",
        "      topics_category_300.append(temp)\n",
        "    count_idxs += 1\n",
        "df_tpc300 = pd.DataFrame(topics_category_300)\n",
        "nmf_training_set_topic = get_top_cat_for_recipe(df_title_val[\"title_clean\"], nmf_embedding)\n",
        "\n",
        "# testing\n",
        "data_samples_test = [' '.join(item) for item in data_words_test]\n",
        "tfidf_vectorizer =  pickle.load(open(\"vectorizer_nmf_07262021.pickle\", 'rb'))     # Load vectorizer\n",
        "tfidf_test = tfidf_vectorizer.transform(data_samples_test)\n",
        "X_new = nmf_300.transform(tfidf_test) # test_embedding\n",
        "categories_for_recipes_test = get_top_cat_for_recipe(data_words_test, X_new)\n",
        "nmf_testing_set_topic = categories_for_recipes_test "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "violation: 1.0\n",
            "violation: 0.09097869529785489\n",
            "violation: 0.040065920104502974\n",
            "violation: 0.02146293049350555\n",
            "violation: 0.011829907184339654\n",
            "violation: 1.0\n",
            "violation: 0.02770199537023639\n",
            "violation: 0.003331260756428162\n",
            "violation: 0.0008261872022965233\n",
            "violation: 0.0002366470064848293\n",
            "violation: 1.0\n",
            "violation: 0.02769128682350449\n",
            "violation: 0.003333673215264265\n",
            "violation: 0.0008225169085590797\n",
            "violation: 0.00022722862291443135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VW-tRSHiTUy"
      },
      "source": [
        "nmf_testing_set_topic = categories_for_recipes_test "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU1gSzNTcJN3",
        "outputId": "b3b71460-74e6-4efa-9bb5-e6223d59cfbb"
      },
      "source": [
        "print(nmf_testing_set_topic)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFSoeq2lRMcN"
      },
      "source": [
        "## Get the combined dataframe including id, title and corresponding topics for training/testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4v-LZyVY9fw"
      },
      "source": [
        "# Just run this function to get combined dataframe\n",
        "def get_combined_dataframe(df_combined, categories_for_recipes):\n",
        "  topic_list = []\n",
        "  topic_idx_list = []\n",
        "  for i in range(len(categories_for_recipes)):\n",
        "    info = categories_for_recipes[i]\n",
        "    if info == \"no_cat\":\n",
        "      topic_list.append(\"No Cat\")\n",
        "      topic_idx_list.append(\"No Cat\")\n",
        "      continue\n",
        "    topic_list.append(info[\"topic\"])\n",
        "    topic_idx_list.append(info[\"topic_idx\"])\n",
        "  df_combined[\"topic\"] = topic_list\n",
        "  df_combined[\"topic_idx\"] = topic_idx_list\n",
        "  return df_combined"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13DVxgonSWbt"
      },
      "source": [
        "# get combined dataframe including id, title, topic, topic index for each row\n",
        "df_training_combined = get_combined_dataframe(training_df, nmf_training_set_topic)\n",
        "df_testing_combined = get_combined_dataframe(testing_df, nmf_testing_set_topic)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzQcJHjzcQW5",
        "outputId": "42431686-edde-4ab0-ee15-16f2a7548f3b"
      },
      "source": [
        "print(df_training_combined)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                id  ... topic_idx\n",
            "0       00011e0b2c  ...       299\n",
            "1       00011fc1f9  ...         4\n",
            "2       000128a538  ...    No Cat\n",
            "3       00025af750  ...       291\n",
            "4       00029df38f  ...        80\n",
            "...            ...  ...       ...\n",
            "155031  fffe6545e6  ...        17\n",
            "155032  fffe89ea7e  ...       278\n",
            "155033  fffebe68b3  ...         2\n",
            "155034  ffff03a753  ...        38\n",
            "155035  ffffbb45d2  ...       201\n",
            "\n",
            "[155036 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-ryhabRKqRA"
      },
      "source": [
        "## Traverse recipe id in df, find cooresponding image - create a dict {img_id : recipe id} & dataframe including all info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtzjlkXdLrLC"
      },
      "source": [
        "# input: recipe id, output: images.jpg(url could be printed here if needed)\n",
        "def recipeid_to_image(recipe_id, print_url = False):\n",
        "    images = []\n",
        "    for food in layer2:\n",
        "        if food.get(\"id\") == recipe_id:\n",
        "            image_list = food.get(\"images\")\n",
        "            for image in image_list:\n",
        "                image_id = image.get(\"id\")\n",
        "                image_url = image.get(\"url\")\n",
        "                if print_url:\n",
        "                    print(image_url) # this could be used for debug\n",
        "                images.append(image_id)\n",
        "            break\n",
        "    return images\n",
        "\n",
        "# input: recipe id, output: recipe details \n",
        "#                          (target_title, target_partition, target_url, target_ingredients, target_instructions)\n",
        "def recipeid_to_details(recipe_id):\n",
        "    target_ingredients = None\n",
        "    target_url = None\n",
        "    target_partition = None\n",
        "    target_title = None\n",
        "    target_instructions = None\n",
        "\n",
        "    for recipe in layer1:\n",
        "        if recipe.get(\"id\") == recipe_id:\n",
        "            target_ingredients = recipe.get(\"ingredients\")\n",
        "            target_url = recipe.get(\"url\") \n",
        "            target_partition = recipe.get(\"partition\")\n",
        "            target_title = recipe.get(\"title\") \n",
        "            target_instructions = recipe.get(\"instructions\") \n",
        "            break\n",
        "    return (target_title, target_partition, target_url, target_ingredients, target_instructions)\n",
        "## layer_2 dict\n",
        "def create_layer2_dict():\n",
        "  layer2_dict = {}\n",
        "  for food in layer2:\n",
        "    recipe_id = food.get(\"id\")\n",
        "    image_list = food.get(\"images\")\n",
        "    image_names = []\n",
        "    for image in image_list:\n",
        "      image_names.append(image[\"id\"])\n",
        "    layer2_dict[recipe_id] = image_names\n",
        "  return layer2_dict\n",
        "\n",
        "def create_image_recipe_dict(this_df, layer2_dict):\n",
        "    img_recipe_dict = {}\n",
        "    for i in range(len(this_df)):\n",
        "        # print(i)\n",
        "        recipe_id = this_df.iloc[i][\"id\"]\n",
        "        recipe_title = this_df.iloc[i][\"title_clean\"]\n",
        "        recipe_topic = this_df.iloc[i][\"topic\"]\n",
        "        recipe_topic_idx = this_df.iloc[i][\"topic_idx\"]\n",
        "        # print(recipe_id)\n",
        "        image_list = layer2_dict.get(recipe_id)\n",
        "        # print(image_list)\n",
        "        if image_list is None:\n",
        "          continue\n",
        "        for image in image_list:\n",
        "            img_recipe_dict[image] = (recipe_id,recipe_title,recipe_topic,recipe_topic_idx )\n",
        "        ## =========== remove this line or modify the number of recipes ==================\n",
        "    return img_recipe_dict\n",
        "\n",
        "def get_dataframe_all_info(df_all_info, dict_all):\n",
        "  index = 0\n",
        "  for key in dict_all:\n",
        "    df_all_info.iloc[index][\"Image name\"] = key\n",
        "    value = dict_all.get(key)\n",
        "    df_all_info.iloc[index][\"Recipe ID\"] = value[0]\n",
        "    df_all_info.iloc[index][\"Title\"] = value[1]\n",
        "    df_all_info.iloc[index][\"Topic\"] = value[2]\n",
        "    df_all_info.iloc[index][\"Topic Index\"] = value[3]\n",
        "    index += 1\n",
        "  return df_all_info"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvsgmiUeU9D8"
      },
      "source": [
        "# get the dataframe with all info, remove \"No cat\", no need to change anything here, just run it\n",
        "layer2_dict = create_layer2_dict()\n",
        "dict_train = create_image_recipe_dict(df_training_combined, layer2_dict)\n",
        "df_all_info_train = pd.DataFrame(index = range(0, len(dict_train)), columns=['Image name','Recipe ID','Title','Topic','Topic Index'])\n",
        "df_all_info_train = get_dataframe_all_info(df_all_info_train, dict_train)\n",
        "df_all_info_train = df_all_info_train[df_all_info_train.Topic != \"No Cat\"]\n",
        "\n",
        "dict_test = create_image_recipe_dict(df_testing_combined, layer2_dict)\n",
        "df_all_info_test = pd.DataFrame(index = range(0, len(dict_test)), columns=['Image name','Recipe ID','Title','Topic','Topic Index'])\n",
        "df_all_info_test = get_dataframe_all_info(df_all_info_test, dict_test)\n",
        "df_all_info_test = df_all_info_test[df_all_info_test.Topic != \"No Cat\"]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBSdqwetl0v8"
      },
      "source": [
        "img_train_list = []\n",
        "topic_train_list = []\n",
        "img_test_list = []\n",
        "topic_test_list = []\n",
        "for i in range(df_all_info_train.shape[0]):\n",
        "  img_train_list.append(df_all_info_train.iloc[i][\"Image name\"])\n",
        "  topic_train_list.append(df_all_info_train.iloc[i][\"Topic Index\"])\n",
        "\n",
        "for i in range(df_all_info_test.shape[0]):\n",
        "  #print(i)\n",
        "  img_test_list.append(df_all_info_test.iloc[i][\"Image name\"])\n",
        "  topic_test_list.append(df_all_info_test.iloc[i][\"Topic Index\"])\n",
        "\n",
        "#img_train_list = df_all_info_train['Image name']\n",
        "#img_test_list = df_all_info_test['Image name']\n",
        "#topic_train_list = df_all_info_train['Topic Index']\n",
        "#topic_test_list = df_all_info_test['Topic Index']"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwqNawGXmObt",
        "outputId": "d65bb16b-e0ce-4674-cf3d-ec1846789435"
      },
      "source": [
        "print(img_train_list[66388], topic_train_list[66388])"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "de78efc3c0.jpg 78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t51yoUDNmQN0",
        "outputId": "55d34ba7-887a-4330-a4c4-264ed4f390ca"
      },
      "source": [
        "print(img_test_list[3], topic_test_list[3])"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1657f23729.jpg 68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "K8Q7vXBfthdi",
        "outputId": "f4503e7b-ed6d-4ee8-8c21-2e060195bbf2"
      },
      "source": [
        "df_all_info_train"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image name</th>\n",
              "      <th>Recipe ID</th>\n",
              "      <th>Title</th>\n",
              "      <th>Topic</th>\n",
              "      <th>Topic Index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>665bbeafc7.jpg</td>\n",
              "      <td>00029f71f7</td>\n",
              "      <td>apple carrot bones  dog treat</td>\n",
              "      <td>[carrot, salad]</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>87aea5035b.jpg</td>\n",
              "      <td>00029f71f7</td>\n",
              "      <td>apple carrot bones  dog treat</td>\n",
              "      <td>[carrot, salad]</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a97924d704.jpg</td>\n",
              "      <td>0004c091a0</td>\n",
              "      <td>whole wheat waffles</td>\n",
              "      <td>[whole, wheat]</td>\n",
              "      <td>122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8e98aee7e1.jpg</td>\n",
              "      <td>000507ca6b</td>\n",
              "      <td>frosty strawberry squares</td>\n",
              "      <td>[cheese, squares]</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7027a5c4f9.jpg</td>\n",
              "      <td>0006354bc3</td>\n",
              "      <td>irresistible peanut butter cookies</td>\n",
              "      <td>[peanut, butter]</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1013</th>\n",
              "      <td>cb21e1895c.jpg</td>\n",
              "      <td>02261f7f0b</td>\n",
              "      <td>mexican inspired tequila coffee</td>\n",
              "      <td>[coffee, coffee, cake]</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1014</th>\n",
              "      <td>74600e26f5.jpg</td>\n",
              "      <td>022697f8d0</td>\n",
              "      <td>roast loin of lamb recipe</td>\n",
              "      <td>[roast, chicken]</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1015</th>\n",
              "      <td>2b6eaa2f35.jpg</td>\n",
              "      <td>022789237c</td>\n",
              "      <td>quick   creamy macaroni   cheese with spinach</td>\n",
              "      <td>[macaroni, salad]</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1016</th>\n",
              "      <td>c41be15d6f.jpg</td>\n",
              "      <td>0229a830a3</td>\n",
              "      <td>beef tenderloin with parmesan prosciutto crisps</td>\n",
              "      <td>[pork, tenderloin]</td>\n",
              "      <td>297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017</th>\n",
              "      <td>0afbf096fc.jpg</td>\n",
              "      <td>022a2181b9</td>\n",
              "      <td>grilled chicken with cherry sauce</td>\n",
              "      <td>[cherry, salad]</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Image name   Recipe ID  ...                   Topic Topic Index\n",
              "0     665bbeafc7.jpg  00029f71f7  ...         [carrot, salad]          98\n",
              "1     87aea5035b.jpg  00029f71f7  ...         [carrot, salad]          98\n",
              "2     a97924d704.jpg  0004c091a0  ...          [whole, wheat]         122\n",
              "3     8e98aee7e1.jpg  000507ca6b  ...       [cheese, squares]         188\n",
              "4     7027a5c4f9.jpg  0006354bc3  ...        [peanut, butter]          10\n",
              "...              ...         ...  ...                     ...         ...\n",
              "1013  cb21e1895c.jpg  02261f7f0b  ...  [coffee, coffee, cake]         120\n",
              "1014  74600e26f5.jpg  022697f8d0  ...        [roast, chicken]         101\n",
              "1015  2b6eaa2f35.jpg  022789237c  ...       [macaroni, salad]         125\n",
              "1016  c41be15d6f.jpg  0229a830a3  ...      [pork, tenderloin]         297\n",
              "1017  0afbf096fc.jpg  022a2181b9  ...         [cherry, salad]          90\n",
              "\n",
              "[1000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "54ApvFAEs3d4",
        "outputId": "d2010403-35ac-4636-f8af-a1fe4566e250"
      },
      "source": [
        "df_all_info_test"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image name</th>\n",
              "      <th>Recipe ID</th>\n",
              "      <th>Title</th>\n",
              "      <th>Topic</th>\n",
              "      <th>Topic Index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3e233001e2.jpg</td>\n",
              "      <td>00003a70b1</td>\n",
              "      <td>crunchy onion potato bake</td>\n",
              "      <td>[potato, salad]</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7f749987f9.jpg</td>\n",
              "      <td>00003a70b1</td>\n",
              "      <td>crunchy onion potato bake</td>\n",
              "      <td>[potato, salad]</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aaf6b2dcd3.jpg</td>\n",
              "      <td>00003a70b1</td>\n",
              "      <td>crunchy onion potato bake</td>\n",
              "      <td>[potato, salad]</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1657f23729.jpg</td>\n",
              "      <td>00047059be</td>\n",
              "      <td>butternut squash soup or bisque  roasting method</td>\n",
              "      <td>[butternut, squash, soup]</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7cd4a0f1a1.jpg</td>\n",
              "      <td>00047059be</td>\n",
              "      <td>butternut squash soup or bisque  roasting method</td>\n",
              "      <td>[butternut, squash, soup]</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1011</th>\n",
              "      <td>2290dd5643.jpg</td>\n",
              "      <td>0272fd4179</td>\n",
              "      <td>garlic shrimp and scallops</td>\n",
              "      <td>[shrimp]</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1012</th>\n",
              "      <td>f799f50b90.jpg</td>\n",
              "      <td>0272fd4179</td>\n",
              "      <td>garlic shrimp and scallops</td>\n",
              "      <td>[shrimp]</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1013</th>\n",
              "      <td>223a5ec68b.jpg</td>\n",
              "      <td>02731ae87a</td>\n",
              "      <td>sugar free sparkling lemonade</td>\n",
              "      <td>[sugar, pie]</td>\n",
              "      <td>165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1014</th>\n",
              "      <td>dd7832ccdb.jpg</td>\n",
              "      <td>02756e915b</td>\n",
              "      <td>courgette and bacon soup recipe</td>\n",
              "      <td>[soup]</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1015</th>\n",
              "      <td>d636a3e995.jpg</td>\n",
              "      <td>0275c142eb</td>\n",
              "      <td>chicken parmesan</td>\n",
              "      <td>[chicken, parmesan]</td>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Image name   Recipe ID  ...                      Topic Topic Index\n",
              "0     3e233001e2.jpg  00003a70b1  ...            [potato, salad]          11\n",
              "1     7f749987f9.jpg  00003a70b1  ...            [potato, salad]          11\n",
              "2     aaf6b2dcd3.jpg  00003a70b1  ...            [potato, salad]          11\n",
              "3     1657f23729.jpg  00047059be  ...  [butternut, squash, soup]          68\n",
              "4     7cd4a0f1a1.jpg  00047059be  ...  [butternut, squash, soup]          68\n",
              "...              ...         ...  ...                        ...         ...\n",
              "1011  2290dd5643.jpg  0272fd4179  ...                   [shrimp]          29\n",
              "1012  f799f50b90.jpg  0272fd4179  ...                   [shrimp]          29\n",
              "1013  223a5ec68b.jpg  02731ae87a  ...               [sugar, pie]         165\n",
              "1014  dd7832ccdb.jpg  02756e915b  ...                     [soup]           4\n",
              "1015  d636a3e995.jpg  0275c142eb  ...        [chicken, parmesan]          89\n",
              "\n",
              "[1000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2IFgQ9FTz8c"
      },
      "source": [
        "## Image loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_yxo0Rjdin4"
      },
      "source": [
        "class im2recipedataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, img_folder_path, partition,data_transform, img_list, label_list):\n",
        "      # load the dataset\n",
        "      self.img_folder_path = img_folder_path\n",
        "      self.partition = partition\n",
        "      self.dataset = img_list\n",
        "      #print(self.dataset.shape[0])\n",
        "      self.label_list = label_list\n",
        "      self.transform = data_transform\n",
        "    \n",
        "    def read_img(self, img_folder_path, partition, image_name):\n",
        "        first_dir = image_name[0]\n",
        "        second_dir = image_name[1]\n",
        "        third_dir = image_name[2]\n",
        "        forth_dir = image_name[3]\n",
        "        final_img_dir = os.path.join(img_folder_path, partition, first_dir, second_dir, third_dir, forth_dir, image_name)\n",
        "        #print(final_img_dir)\n",
        "        img = cv2.imread(final_img_dir)\n",
        "        img_new = cv2.resize(img, dsize=(299, 299), interpolation=cv2.INTER_CUBIC)\n",
        "        return img_new\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data_name = self.dataset[idx]\n",
        "        #print(data_name)\n",
        "        img = self.read_img(self.img_folder_path, self.partition, data_name)\n",
        "        #plt.imshow(img)\n",
        "        #print(img.shape)\n",
        "        label = self.label_list[idx]\n",
        "        #print(label)\n",
        "        #print(idx)\n",
        "        return self.transform(img), label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UGPGThBpeX1"
      },
      "source": [
        "input_size = 299\n",
        "transform_train = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "transform_val = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTGJlK_6puxK"
      },
      "source": [
        "img_path_train = \"/content/gdrive/My Drive/2021 Summer CS7643 Share Folder/data/images\"\n",
        "partiton_train = \"val\"\n",
        "train_set = im2recipedataset(img_path_train, partiton_train, transform_train ,img_train_list, topic_train_list)\n",
        "partiton_val = \"test\"\n",
        "valid_set = im2recipedataset(img_path_train, partiton_val, transform_train ,img_test_list, topic_test_list)\n",
        "train_dataloader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_set, batch_size=16, shuffle=True)\n",
        "dataloaders_dict = {\"train\":train_dataloader, \"val\": valid_dataloader}"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arBmanG0sC8i",
        "outputId": "71065bd6-ea39-40fa-e967-231ff9771bd7"
      },
      "source": [
        "print(train_set.__getitem__(5))\n",
        "#print(valid_set.__getitem__(2))"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[[ 0.4337,  0.3481,  0.2796,  ...,  1.8379,  1.8893,  1.8722],\n",
            "         [ 0.3652,  0.3652,  0.2624,  ...,  1.9064,  1.9749,  1.9235],\n",
            "         [ 0.3823,  0.3652,  0.2967,  ...,  1.9064,  1.9235,  1.8550],\n",
            "         ...,\n",
            "         [-1.7240, -1.7412, -1.7069,  ...,  1.5125,  1.5297,  1.8037],\n",
            "         [-1.7412, -1.7412, -1.7240,  ...,  1.4269,  1.5297,  1.6667],\n",
            "         [-1.7240, -1.7412, -1.7240,  ...,  1.4098,  1.5125,  1.6153]],\n",
            "\n",
            "        [[-0.8277, -0.8978, -0.9853,  ...,  1.6232,  1.7283,  1.7283],\n",
            "         [-0.8627, -0.8452, -0.9678,  ...,  1.7108,  1.8158,  1.7633],\n",
            "         [-0.8452, -0.8277, -0.8978,  ...,  1.7283,  1.7283,  1.6758],\n",
            "         ...,\n",
            "         [-1.6506, -1.6856, -1.6506,  ...,  0.1352,  0.1702,  0.4503],\n",
            "         [-1.6681, -1.6856, -1.6681,  ...,  0.0476,  0.1176,  0.2577],\n",
            "         [-1.6856, -1.6856, -1.6681,  ...,  0.0826,  0.1527,  0.2227]],\n",
            "\n",
            "        [[-0.6018, -0.7238, -0.6890,  ...,  1.5594,  1.7163,  1.7337],\n",
            "         [-0.7064, -0.6715, -0.6367,  ...,  1.6117,  1.7163,  1.6988],\n",
            "         [-0.4973, -0.6193, -0.6541,  ...,  1.6291,  1.6640,  1.6117],\n",
            "         ...,\n",
            "         [-1.4907, -1.4733, -1.4384,  ...,  0.2696,  0.3045,  0.5834],\n",
            "         [-1.5081, -1.4733, -1.4559,  ...,  0.2173,  0.3742,  0.5311],\n",
            "         [-1.5256, -1.4733, -1.4559,  ...,  0.2173,  0.4091,  0.6182]]]), 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZXS4SIZzTOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f97b0ab0-8008-40a8-a47e-a3f61c1a92cb"
      },
      "source": [
        "# ref: https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "def initialize_model(num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model_ft, feature_extract)\n",
        "    # Handle the auxilary net\n",
        "    num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "    model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "    # Handle the primary net\n",
        "    num_ftrs = model_ft.fc.in_features\n",
        "    model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
        "    input_size = 299\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "\n",
        "#  Flag for feature extracting. When False, we finetune the whole model,\n",
        "#  when True we only update the reshaped layer params\n",
        "feature_extract = True\n",
        "\n",
        "# Initialize the model for this run\n",
        "InceptionV3, input_size = initialize_model(300, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "#print(InceptionV3)\n",
        "\n",
        "# https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "# Send the model to GPU\n",
        "InceptionV3 = InceptionV3.to(device)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMtzWQ56zaXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3efafb5a-f7ed-4133-9dc9-88bf5c6c32c5"
      },
      "source": [
        "# parameter for model hyperparameter tuning\n",
        "learning_rate = 0.001\n",
        "momentum_value = 0.9\n",
        "criterion_type = nn.CrossEntropyLoss()\n",
        "num_epochs = 200\n",
        "\n",
        "#=============================================\n",
        "\n",
        "params_to_update = InceptionV3.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in InceptionV3.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=learning_rate , momentum=momentum_value)\n",
        "# Setup the loss fxn\n",
        "criterion = criterion_type"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t AuxLogits.fc.weight\n",
            "\t AuxLogits.fc.bias\n",
            "\t fc.weight\n",
            "\t fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnduYUtvzabd"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "    \n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            \n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                inputs = inputs.type(torch.cuda.FloatTensor)\n",
        "                #print(inputs.shape)\n",
        "                labels = torch.squeeze(labels)\n",
        "                labels = labels.to(device)\n",
        "                #print(labels.shape)\n",
        "                #outputs, aux_outputs = model(inputs)\n",
        "                #print(outputs.shape)\n",
        "                #print(aux_outputs.shape)\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JbA_9SCzae3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "fe8e6abe-f919-477b-cf94-e21c4e6e830f"
      },
      "source": [
        "# Train and evaluate\n",
        "model_ft, hist = train_model(InceptionV3, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=True)"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/199\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-219-17f7ad35aa1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInceptionV3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_inception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-218-3754c7700fee>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, num_epochs, is_inception)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# Iterate over data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-206-1c5869e35f38>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mdata_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m#print(data_name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_folder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;31m#plt.imshow(img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#print(img.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-206-1c5869e35f38>\u001b[0m in \u001b[0;36mread_img\u001b[0;34m(self, img_folder_path, partition, image_name)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mfinal_img_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_folder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthird_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforth_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#print(final_img_dir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_img_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mimg_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m299\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}