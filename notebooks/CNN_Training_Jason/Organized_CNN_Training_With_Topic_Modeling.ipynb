{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Organized_CNN_Training_With_Topic_Modeling","provenance":[{"file_id":"1d9SjG5-0_wGLfwJFZUsvysBUnb4sv7NS","timestamp":1627050747617}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"770bfd7c74a1455bb2fcc70ce0ae7865":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0792a6be37154b109420a93e08baaa0c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1056c12e35f4455babde95ccbe94e491","IPY_MODEL_a9e0a078c7384748bc9d3ad5d9d180c5"]}},"0792a6be37154b109420a93e08baaa0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1056c12e35f4455babde95ccbe94e491":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c1ad7ec90cb346299e795a099b9dcbe0","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":108949747,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":108949747,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0bec13bdb984489699a67f6c6db2b458"}},"a9e0a078c7384748bc9d3ad5d9d180c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_10b12e271fd449ae8e554fc1da9436f0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 104M/104M [00:01&lt;00:00, 71.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_944534c0e74e4e0bafaf3cd954adc0f3"}},"c1ad7ec90cb346299e795a099b9dcbe0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0bec13bdb984489699a67f6c6db2b458":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"10b12e271fd449ae8e554fc1da9436f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"944534c0e74e4e0bafaf3cd954adc0f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"Ulkqg44lPcVP"},"source":["## Conduct the CNN model training based on the im2recipe image dataset and the topic modeling(NMF)"]},{"cell_type":"markdown","metadata":{"id":"dXIAqoeb1VIR"},"source":["## Import 1.Module  2.Layer1&Layer2 json  3.Create title cleaned validation & test dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rvG8xCqQ1ZUd","executionInfo":{"status":"ok","timestamp":1627366277664,"user_tz":420,"elapsed":71967,"user":{"displayName":"Hung-Hsi Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLbZz3jls7cHNGm2KOXKxMPMSbV2b16XtapDc9NQ=s64","userId":"08494907576091059468"}},"outputId":"3a862ba7-bf4f-455a-910d-35793da18a39"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","import os, csv\n","import json  \n","import pandas as pd\n","import numpy as np\n","import re\n","import gensim\n","from gensim.utils import simple_preprocess\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","import gensim.corpora as corpora\n","from operator import itemgetter\n","import operator\n","import pickle\n","from sklearn.manifold import TSNE\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.decomposition import NMF\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as data\n","import torchvision\n","from torchvision import models, transforms\n","import cv2\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader \n","import time\n","import copy\n","import torch.nn.functional as F\n","os.chdir(\"/content/gdrive/My Drive/2021 Summer CS7643 Share Folder/data/recipe1M\")\n","layer1 = json.load(open(\"layer1.json\", \"r\"))\n","layer2 = json.load(open(\"layer2.json\", \"r\"))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sTYWtAhf_UTM","executionInfo":{"status":"ok","timestamp":1627366294609,"user_tz":420,"elapsed":4897,"user":{"displayName":"Hung-Hsi Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLbZz3jls7cHNGm2KOXKxMPMSbV2b16XtapDc9NQ=s64","userId":"08494907576091059468"}}},"source":["# create title cleaned dataframe for val/test dataset, please enter true or false\n","create_val_df = True\n","create_test_df = True\n","create_train_df = False\n","\n","# No need to enter, just to store dataframe in case we need it for visualization\n","df_title_val = None # dataframe with cleaned title for validation dataset\n","df_title_test = None # dataframe with cleaned title for test dataset\n","df_title_traing = None # dataframe with cleaned title for test dataset\n","\n","\n","# ======== No need to modify code below ============================================\n","# function to create the cleaned title dataframe work\n","def create_clean_titled_df(data_type): # datatype should be either \"val\" or \"test\"\n","  layer1_data_list = []\n","  for i in range(len(layer1)):\n","    temp = {}\n","    if layer1[i][\"partition\"] == data_type:\n","      temp[\"id\"] = layer1[i][\"id\"]\n","      temp['title'] = layer1[i]['title']\n","      layer1_data_list.append(temp)\n","  df_title = pd.DataFrame(layer1_data_list)\n","  # Remove everything that is not alphanumeric or underscore\n","  df_title['title_clean'] = df_title['title'].apply(lambda x: re.sub(r'[^\\w]', ' ', x))\n","  # Convert the titles to lowercase\n","  df_title['title_clean'] = df_title['title_clean'].apply(lambda x: x.lower())\n","  return df_title\n","\n","if create_val_df:\n","  df_title_val = create_clean_titled_df(\"val\")\n","  df_title_val.to_csv(\"layer1_title_val.csv\")\n","if create_test_df:\n","  df_title_test = create_clean_titled_df(\"test\")\n","  df_title_test.to_csv(\"layer1_title_test.csv\")\n","if create_train_df:\n","  df_title_train = create_clean_titled_df(\"train\")\n","  df_title_train.to_csv(\"layer1_title_train.csv\")"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I_yUQHwbUwjd"},"source":["## Apply topic modeling on val/test dataset for categorization"]},{"cell_type":"code","metadata":{"id":"kODVfFzvDs-Z","executionInfo":{"status":"ok","timestamp":1627366297009,"user_tz":420,"elapsed":198,"user":{"displayName":"Hung-Hsi Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLbZz3jls7cHNGm2KOXKxMPMSbV2b16XtapDc9NQ=s64","userId":"08494907576091059468"}}},"source":["def sent_to_words(sentences):\n","    for sentence in sentences:\n","        # deacc=True removes punctuations\n","        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n","def remove_stopwords(texts):\n","    return [[word.strip() for word in simple_preprocess(str(doc)) \n","             if word.strip() not in stop_words] for doc in texts]\n","def get_top_cat_for_recipe(recipes_all_list, w_vector):\n","    final_recipes_cat_name = []\n","    recipe_cat_link = []\n","    for r in range(len(recipes_all_list)):\n","        one_hot_matrix = w_vector[r,:]\n","        all_zeros = not one_hot_matrix.any() # no fitting category\n","        if all_zeros: recipe_cat_link.append(-1) # no fitting category\n","        else:\n","            top_indic = np.argsort(one_hot_matrix)[::-1][0] # 1. umdrehen 2. return erste\n","            recipe_cat_link.append(top_indic)\n","    for num in recipe_cat_link:\n","        if num == -1: final_recipes_cat_name.append('no_cat')\n","        else: final_recipes_cat_name.append(topics_category_300[num])\n","    return final_recipes_cat_name\n","def topic_ext (list_dic):\n","  new_list = []\n","  for i in list_dic:\n","    if i == \"no_cat\":\n","      new_list.append(i)\n","    else:\n","      new_list.append(i['topic'])\n","  return new_list"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rhZFriZX37oW","executionInfo":{"status":"ok","timestamp":1627366703661,"user_tz":420,"elapsed":395696,"user":{"displayName":"Hung-Hsi Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLbZz3jls7cHNGm2KOXKxMPMSbV2b16XtapDc9NQ=s64","userId":"08494907576091059468"}},"outputId":"04baea2e-15c0-4512-e553-a4be7cea8b66"},"source":["# build the nmf model for topic categorization\n","training_data = \"val\" # argument: \"val\", \"test\", \"train\"\n","testing_data = \"test\" # argument: \"val\", \"test\", \"train\"\n","training_df = None # to be assigned based on the training_data argument\n","testing_df = None # to be assigned based on the testing_data argument\n","\n","n_topics = 300 # number of topics\n","nmf_model = None # built NMF model, no need to enter\n","\n","nmf_training_set_topic = None # topic for each row in training set\n","nmf_testing_set_topic = None # topic for each row in testing set\n","\n","# ======== No need to modify code below ======================================================\n","# get the corresponding topic for trainig and testing dataset\n","if training_data == \"val\":\n","  training_df = df_title_val\n","elif training_data == \"train\":\n","  training_df = df_title_traing\n","elif training_data == \"test\":\n","  training_df = df_title_test\n","if testing_data == \"val\":\n","  testing_df = df_title_val\n","elif testing_data == \"train\":\n","  testing_df = df_title_traing\n","elif testing_data == \"test\":\n","  testing_df = df_title_test\n","\n","# creating files for training and validation\n","df_title_val = pd.read_csv(\"layer1_title_val.csv\")\n","df_title_test = pd.read_csv(\"layer1_title_test.csv\")\n","stop_words = stopwords.words('english')\n","stop_words.extend(['from', 'with', 'and', 'recipe', 'in', 'a', 's'])\n","data = training_df[\"title_clean\"].values.tolist()\n","data_words = list(sent_to_words(data))\n","data_words = remove_stopwords(data_words)\n","data_test = testing_df[\"title_clean\"].values.tolist()\n","data_words_test = list(sent_to_words(data_test))\n","data_words_test = remove_stopwords(data_words_test)\n","# building nmf model\n","data_samples = [' '.join(item) for item in data_words]\n","tfidf_vectorizer = TfidfVectorizer(max_df=0.99, max_features=None)\n","tfidf = tfidf_vectorizer.fit_transform(data_samples) #tfidf.shape #(144128, 21930)\n","tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n","pickle.dump(tfidf_vectorizer, open(\"vectorizer_nmf_07262021.pickle\", \"wb\")) #Save vectorizer\n","nmf_300 = NMF(n_components=n_topics, random_state=1, alpha=.1, l1_ratio=.5, verbose=2, max_iter=5).fit(tfidf)\n","nmf_embedding = nmf_300.transform(tfidf) #W matitx \n","# get topcis\n","top_idx = np.argsort(nmf_embedding,axis=0)[-1:]\n","show_300 = 300\n","count_idxs = 0\n","final_names = data_words\n","topics_category_300 = []\n","for idxs in top_idx.T:\n","    if count_idxs == show_300: break\n","    for idx in idxs:\n","      temp = {}\n","      temp[\"topic_idx\"] = count_idxs\n","      temp[\"topic\"] = final_names[idx]\n","      topics_category_300.append(temp)\n","    count_idxs += 1\n","df_tpc300 = pd.DataFrame(topics_category_300)\n","nmf_training_set_topic = get_top_cat_for_recipe(df_title_val[\"title_clean\"], nmf_embedding)\n","\n","# testing\n","data_samples_test = [' '.join(item) for item in data_words_test]\n","tfidf_vectorizer =  pickle.load(open(\"vectorizer_nmf_07262021.pickle\", 'rb'))     # Load vectorizer\n","tfidf_test = tfidf_vectorizer.transform(data_samples_test)\n","X_new = nmf_300.transform(tfidf_test) # test_embedding\n","categories_for_recipes_test = get_top_cat_for_recipe(data_words_test, X_new)\n","nmf_testing_set_topic = categories_for_recipes_test "],"execution_count":4,"outputs":[{"output_type":"stream","text":["violation: 1.0\n","violation: 0.09097869529785488\n","violation: 0.04006592010450302\n","violation: 0.02146293049350556\n","violation: 0.011829907184339659\n","violation: 1.0\n","violation: 0.02770199537023632\n","violation: 0.0033312607564281436\n","violation: 0.0008261872022965138\n","violation: 0.00023664700648482907\n","violation: 1.0\n","violation: 0.027691286823504472\n","violation: 0.0033336732152642583\n","violation: 0.0008225169085590705\n","violation: 0.0002272286229144311\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_VW-tRSHiTUy","executionInfo":{"status":"ok","timestamp":1627366713396,"user_tz":420,"elapsed":150,"user":{"displayName":"Hung-Hsi Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLbZz3jls7cHNGm2KOXKxMPMSbV2b16XtapDc9NQ=s64","userId":"08494907576091059468"}}},"source":["nmf_testing_set_topic = categories_for_recipes_test "],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sFSoeq2lRMcN"},"source":["## Get the combined dataframe including id, title and corresponding topics for training/testing dataset"]},{"cell_type":"code","metadata":{"id":"e4v-LZyVY9fw","executionInfo":{"status":"ok","timestamp":1627366717436,"user_tz":420,"elapsed":191,"user":{"displayName":"Hung-Hsi Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLbZz3jls7cHNGm2KOXKxMPMSbV2b16XtapDc9NQ=s64","userId":"08494907576091059468"}}},"source":["# Just run this function to get combined dataframe\n","def get_combined_dataframe(df_combined, categories_for_recipes):\n","  topic_list = []\n","  topic_idx_list = []\n","  for i in range(len(categories_for_recipes)):\n","    info = categories_for_recipes[i]\n","    if info == \"no_cat\":\n","      topic_list.append(\"No Cat\")\n","      topic_idx_list.append(\"No Cat\")\n","      continue\n","    topic_list.append(info[\"topic\"])\n","    topic_idx_list.append(info[\"topic_idx\"])\n","  df_combined[\"topic\"] = topic_list\n","  df_combined[\"topic_idx\"] = topic_idx_list\n","  return df_combined"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"13DVxgonSWbt","executionInfo":{"status":"ok","timestamp":1627366720043,"user_tz":420,"elapsed":363,"user":{"displayName":"Hung-Hsi Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLbZz3jls7cHNGm2KOXKxMPMSbV2b16XtapDc9NQ=s64","userId":"08494907576091059468"}}},"source":["# get combined dataframe including id, title, topic, topic index for each row\n","df_training_combined = get_combined_dataframe(training_df, nmf_training_set_topic)\n","df_testing_combined = get_combined_dataframe(testing_df, nmf_testing_set_topic)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5-ryhabRKqRA"},"source":["## Traverse recipe id in df, find cooresponding image - create a dict {img_id : recipe id} & dataframe including all info"]},{"cell_type":"code","metadata":{"id":"LtzjlkXdLrLC","executionInfo":{"status":"ok","timestamp":1627366786501,"user_tz":420,"elapsed":229,"user":{"displayName":"Hung-Hsi Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLbZz3jls7cHNGm2KOXKxMPMSbV2b16XtapDc9NQ=s64","userId":"08494907576091059468"}}},"source":["# input: recipe id, output: images.jpg(url could be printed here if needed)\n","def recipeid_to_image(recipe_id, print_url = False):\n","    images = []\n","    for food in layer2:\n","        if food.get(\"id\") == recipe_id:\n","            image_list = food.get(\"images\")\n","            for image in image_list:\n","                image_id = image.get(\"id\")\n","                image_url = image.get(\"url\")\n","                if print_url:\n","                    print(image_url) # this could be used for debug\n","                images.append(image_id)\n","            break\n","    return images\n","\n","# input: recipe id, output: recipe details \n","#                          (target_title, target_partition, target_url, target_ingredients, target_instructions)\n","def recipeid_to_details(recipe_id):\n","    target_ingredients = None\n","    target_url = None\n","    target_partition = None\n","    target_title = None\n","    target_instructions = None\n","\n","    for recipe in layer1:\n","        if recipe.get(\"id\") == recipe_id:\n","            target_ingredients = recipe.get(\"ingredients\")\n","            target_url = recipe.get(\"url\") \n","            target_partition = recipe.get(\"partition\")\n","            target_title = recipe.get(\"title\") \n","            target_instructions = recipe.get(\"instructions\") \n","            break\n","    return (target_title, target_partition, target_url, target_ingredients, target_instructions)\n","## layer_2 dict\n","def create_layer2_dict():\n","  layer2_dict = {}\n","  for food in layer2:\n","    recipe_id = food.get(\"id\")\n","    image_list = food.get(\"images\")\n","    image_names = []\n","    for image in image_list:\n","      image_names.append(image[\"id\"])\n","    layer2_dict[recipe_id] = image_names\n","  return layer2_dict\n","\n","def create_image_recipe_dict(this_df, layer2_dict):\n","    img_recipe_dict = {}\n","    for i in range(len(this_df)):\n","        # print(i)\n","        recipe_id = this_df.iloc[i][\"id\"]\n","        recipe_title = this_df.iloc[i][\"title_clean\"]\n","        recipe_topic = this_df.iloc[i][\"topic\"]\n","        recipe_topic_idx = this_df.iloc[i][\"topic_idx\"]\n","        # print(recipe_id)\n","        image_list = layer2_dict.get(recipe_id)\n","        # print(image_list)\n","        if image_list is None:\n","          continue\n","        for image in image_list:\n","            img_recipe_dict[image] = (recipe_id,recipe_title,recipe_topic,recipe_topic_idx )\n","        ## =========== remove this line or modify the number of recipes ==================\n","    return img_recipe_dict\n","\n","def get_dataframe_all_info(df_all_info, dict_all):\n","  index = 0\n","  for key in dict_all:\n","    df_all_info.iloc[index][\"Image name\"] = key\n","    value = dict_all.get(key)\n","    df_all_info.iloc[index][\"Recipe ID\"] = value[0]\n","    df_all_info.iloc[index][\"Title\"] = value[1]\n","    df_all_info.iloc[index][\"Topic\"] = value[2]\n","    df_all_info.iloc[index][\"Topic Index\"] = value[3]\n","    index += 1\n","  return df_all_info"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"AvsgmiUeU9D8","executionInfo":{"status":"ok","timestamp":1627368712718,"user_tz":420,"elapsed":69638,"user":{"displayName":"Hung-Hsi Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLbZz3jls7cHNGm2KOXKxMPMSbV2b16XtapDc9NQ=s64","userId":"08494907576091059468"}}},"source":["# get the dataframe with all info, remove \"No cat\", no need to change anything here, just run it\n","layer2_dict = create_layer2_dict()\n","dict_train = create_image_recipe_dict(df_training_combined, layer2_dict)\n","df_all_info_train = pd.DataFrame(index = range(0, len(dict_train)), columns=['Image name','Recipe ID','Title','Topic','Topic Index'])\n","df_all_info_train = get_dataframe_all_info(df_all_info_train, dict_train)\n","df_all_info_train = df_all_info_train[df_all_info_train.Topic != \"No Cat\"]\n","\n","dict_test = create_image_recipe_dict(df_testing_combined, layer2_dict)\n","df_all_info_test = pd.DataFrame(index = range(0, len(dict_test)), columns=['Image name','Recipe ID','Title','Topic','Topic Index'])\n","df_all_info_test = get_dataframe_all_info(df_all_info_test, dict_test)\n","df_all_info_test = df_all_info_test[df_all_info_test.Topic != \"No Cat\"]"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"9y61oglucH5J","executionInfo":{"status":"ok","timestamp":1627368752620,"user_tz":420,"elapsed":146,"user":{"displayName":"Hung-Hsi Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLbZz3jls7cHNGm2KOXKxMPMSbV2b16XtapDc9NQ=s64","userId":"08494907576091059468"}}},"source":["# shrinking size (don't run this cell if you are running a full training)\n","saved_info = df_all_info_train.copy()\n","shrinked_data_size = 1000\n","df_all_info_train = df_all_info_train[0:shrinked_data_size]\n","df_all_info_test = df_all_info_test[0:shrinked_data_size]"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"K8Q7vXBfthdi","executionInfo":{"status":"ok","timestamp":1627368755272,"user_tz":420,"elapsed":179,"user":{"displayName":"Hung-Hsi Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLbZz3jls7cHNGm2KOXKxMPMSbV2b16XtapDc9NQ=s64","userId":"08494907576091059468"}},"outputId":"3eb9d523-5fd2-49a6-beaf-265dda3f0a96"},"source":["df_all_info_train"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Image name</th>\n","      <th>Recipe ID</th>\n","      <th>Title</th>\n","      <th>Topic</th>\n","      <th>Topic Index</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>665bbeafc7.jpg</td>\n","      <td>00029f71f7</td>\n","      <td>apple carrot bones  dog treat</td>\n","      <td>[carrot, salad]</td>\n","      <td>98</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>87aea5035b.jpg</td>\n","      <td>00029f71f7</td>\n","      <td>apple carrot bones  dog treat</td>\n","      <td>[carrot, salad]</td>\n","      <td>98</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>a97924d704.jpg</td>\n","      <td>0004c091a0</td>\n","      <td>whole wheat waffles</td>\n","      <td>[whole, wheat]</td>\n","      <td>122</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>8e98aee7e1.jpg</td>\n","      <td>000507ca6b</td>\n","      <td>frosty strawberry squares</td>\n","      <td>[cheese, squares]</td>\n","      <td>188</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7027a5c4f9.jpg</td>\n","      <td>0006354bc3</td>\n","      <td>irresistible peanut butter cookies</td>\n","      <td>[peanut, butter]</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>505</th>\n","      <td>e8cec314fa.jpg</td>\n","      <td>01103b5d1b</td>\n","      <td>cocktail grilled cheese appetizers</td>\n","      <td>[cocktail]</td>\n","      <td>273</td>\n","    </tr>\n","    <tr>\n","      <th>506</th>\n","      <td>3352c4126b.jpg</td>\n","      <td>0110c9c88d</td>\n","      <td>grilled honey lemon chicken</td>\n","      <td>[lemon, lemon, chicken]</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>507</th>\n","      <td>375e1cb026.jpg</td>\n","      <td>0110c9c88d</td>\n","      <td>grilled honey lemon chicken</td>\n","      <td>[lemon, lemon, chicken]</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>508</th>\n","      <td>5178c517f6.jpg</td>\n","      <td>0110c9c88d</td>\n","      <td>grilled honey lemon chicken</td>\n","      <td>[lemon, lemon, chicken]</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>509</th>\n","      <td>69fd3e22eb.jpg</td>\n","      <td>0110c9c88d</td>\n","      <td>grilled honey lemon chicken</td>\n","      <td>[lemon, lemon, chicken]</td>\n","      <td>22</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>500 rows Ã— 5 columns</p>\n","</div>"],"text/plain":["         Image name   Recipe ID  ...                    Topic Topic Index\n","0    665bbeafc7.jpg  00029f71f7  ...          [carrot, salad]          98\n","1    87aea5035b.jpg  00029f71f7  ...          [carrot, salad]          98\n","2    a97924d704.jpg  0004c091a0  ...           [whole, wheat]         122\n","3    8e98aee7e1.jpg  000507ca6b  ...        [cheese, squares]         188\n","4    7027a5c4f9.jpg  0006354bc3  ...         [peanut, butter]          10\n","..              ...         ...  ...                      ...         ...\n","505  e8cec314fa.jpg  01103b5d1b  ...               [cocktail]         273\n","506  3352c4126b.jpg  0110c9c88d  ...  [lemon, lemon, chicken]          22\n","507  375e1cb026.jpg  0110c9c88d  ...  [lemon, lemon, chicken]          22\n","508  5178c517f6.jpg  0110c9c88d  ...  [lemon, lemon, chicken]          22\n","509  69fd3e22eb.jpg  0110c9c88d  ...  [lemon, lemon, chicken]          22\n","\n","[500 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"54ApvFAEs3d4","executionInfo":{"status":"ok","timestamp":1627368757082,"user_tz":420,"elapsed":157,"user":{"displayName":"Hung-Hsi Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLbZz3jls7cHNGm2KOXKxMPMSbV2b16XtapDc9NQ=s64","userId":"08494907576091059468"}},"outputId":"1d22d9c5-a541-45f6-da0a-dd286c47a67f"},"source":["df_all_info_test"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Image name</th>\n","      <th>Recipe ID</th>\n","      <th>Title</th>\n","      <th>Topic</th>\n","      <th>Topic Index</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3e233001e2.jpg</td>\n","      <td>00003a70b1</td>\n","      <td>crunchy onion potato bake</td>\n","      <td>[potato, salad]</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7f749987f9.jpg</td>\n","      <td>00003a70b1</td>\n","      <td>crunchy onion potato bake</td>\n","      <td>[potato, salad]</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>aaf6b2dcd3.jpg</td>\n","      <td>00003a70b1</td>\n","      <td>crunchy onion potato bake</td>\n","      <td>[potato, salad]</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1657f23729.jpg</td>\n","      <td>00047059be</td>\n","      <td>butternut squash soup or bisque  roasting method</td>\n","      <td>[butternut, squash, soup]</td>\n","      <td>68</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7cd4a0f1a1.jpg</td>\n","      <td>00047059be</td>\n","      <td>butternut squash soup or bisque  roasting method</td>\n","      <td>[butternut, squash, soup]</td>\n","      <td>68</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>501</th>\n","      <td>6e11dc989e.jpg</td>\n","      <td>015dabf338</td>\n","      <td>baked pumpkin rice pudding</td>\n","      <td>[pumpkin, salad]</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>502</th>\n","      <td>a3beac4cf6.jpg</td>\n","      <td>015dabf338</td>\n","      <td>baked pumpkin rice pudding</td>\n","      <td>[pumpkin, salad]</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>503</th>\n","      <td>de41580774.jpg</td>\n","      <td>016067d95e</td>\n","      <td>green ceviche with cucumber</td>\n","      <td>[green]</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>504</th>\n","      <td>6b465ab497.jpg</td>\n","      <td>01611a82ea</td>\n","      <td>easy tiramisu cup</td>\n","      <td>[easy, easy, fruit, salad]</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>505</th>\n","      <td>02a109811b.jpg</td>\n","      <td>0161b6a28d</td>\n","      <td>classic bisquicktm peach cobbler</td>\n","      <td>[cobbler]</td>\n","      <td>266</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>500 rows Ã— 5 columns</p>\n","</div>"],"text/plain":["         Image name   Recipe ID  ...                       Topic Topic Index\n","0    3e233001e2.jpg  00003a70b1  ...             [potato, salad]          11\n","1    7f749987f9.jpg  00003a70b1  ...             [potato, salad]          11\n","2    aaf6b2dcd3.jpg  00003a70b1  ...             [potato, salad]          11\n","3    1657f23729.jpg  00047059be  ...   [butternut, squash, soup]          68\n","4    7cd4a0f1a1.jpg  00047059be  ...   [butternut, squash, soup]          68\n","..              ...         ...  ...                         ...         ...\n","501  6e11dc989e.jpg  015dabf338  ...            [pumpkin, salad]          28\n","502  a3beac4cf6.jpg  015dabf338  ...            [pumpkin, salad]          28\n","503  de41580774.jpg  016067d95e  ...                     [green]          36\n","504  6b465ab497.jpg  01611a82ea  ...  [easy, easy, fruit, salad]          14\n","505  02a109811b.jpg  0161b6a28d  ...                   [cobbler]         266\n","\n","[500 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"z2IFgQ9FTz8c"},"source":["## Image loading"]},{"cell_type":"code","metadata":{"id":"CYuy8wZMa4V2"},"source":["# add image_name to topic index dict so that searching by image_name is easier\n","image_index_dict_train = {}\n","\n","for i in range(len(df_all_info_train)):\n","  image_name = df_all_info_train.iloc[i][\"Image name\"]\n","  topic_idx = df_all_info_train.iloc[i][\"Topic Index\"]\n","  image_index_dict_train[image_name] = topic_idx \n","\n","image_index_dict_test = {}\n","for i in range(len(df_all_info_test)):\n","  image_name = df_all_info_test.iloc[i][\"Image name\"]\n","  topic_idx = df_all_info_test.iloc[i][\"Topic Index\"]\n","  image_index_dict_test[image_name] = topic_idx "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-yyAfWu4y7vv","executionInfo":{"status":"ok","timestamp":1627367794989,"user_tz":420,"elapsed":507922,"user":{"displayName":"Hung-Hsi Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLbZz3jls7cHNGm2KOXKxMPMSbV2b16XtapDc9NQ=s64","userId":"08494907576091059468"}}},"source":["####### IMPORTANT LIST FOR TRAINING ##########\n","img_array_list = []\n","label_list = []\n","img_dir = \"/content/gdrive/My Drive/2021 Summer CS7643 Share Folder/data/images/val\"\n","\n","############################################\n","def read_image(image_dir, target_img_name):\n","  first_dir = target_img_name[0]\n","  second_dir = target_img_name[1]\n","  third_dir = target_img_name[2]\n","  forth_dir = target_img_name[3]\n","  final_img_dir = image_dir + \"/\" + first_dir + \"/\" + second_dir + \"/\" + third_dir + \"/\" + forth_dir + \"/\" + target_img_name\n","  img = plt.imread(final_img_dir)\n","  return img\n","\n","\n","df_all_info_with_cat = df_all_info_train\n","# traverse all row in df_mini_batch and append the image array & title into list\n","for i in range(df_all_info_with_cat.shape[0]):\n","  selected_row = df_all_info_with_cat.iloc[i] # select ith row in df_mini_batch\n","  selected_label = selected_row[\"Topic Index\"]\n","  selected_img_name = selected_row[\"Image name\"]\n","  img_array = read_image(img_dir, selected_img_name) # return a (h,w,channel) np array\n","  # append into list\n","  img_array_list.append(img_array)\n","  label_list.append(selected_label)\n","\n","# Create data for training from the list\n","my_x = np.zeros((len(img_array_list), 299, 299, 3)) # Inception accepts (299,299,3) image\n","for i in range(len(img_array_list)):\n","  img_new = cv2.resize(img_array_list[i], dsize=(299, 299), interpolation=cv2.INTER_CUBIC)\n","  my_x[i] = img_new\n","# Create label for training from the list\n","label = np.zeros((df_all_info_with_cat.shape[0], 1))\n","i = 0\n","for index, row in df_all_info_with_cat.iterrows():\n","    label[i] = df_all_info_with_cat[\"Topic Index\"][index]\n","    #print(i,label[i])\n","    i += 1\n","label = label.astype(int)\n","label_encoded = F.one_hot(torch.tensor(label), num_classes=300)\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"8a8NE10rsACO","executionInfo":{"status":"ok","timestamp":1627369266055,"user_tz":420,"elapsed":501402,"user":{"displayName":"Hung-Hsi Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLbZz3jls7cHNGm2KOXKxMPMSbV2b16XtapDc9NQ=s64","userId":"08494907576091059468"}}},"source":["####### IMPORTANT LIST FOR TESTING ##########\n","img_array_list_test = []\n","label_list_test = []\n","img_dir_test = \"/content/gdrive/My Drive/2021 Summer CS7643 Share Folder/data/images/test\"\n","\n","############################################\n","\n","# traverse all row in df_mini_batch and append the image array & title into list\n","for i in range(df_all_info_test.shape[0]):\n","  selected_row = df_all_info_test.iloc[i] # select ith row in df_mini_batch\n","  selected_label = selected_row[\"Topic Index\"]\n","  selected_img_name = selected_row[\"Image name\"]\n","  img_array = read_image(img_dir_test, selected_img_name) # return a (h,w,channel) np array\n","  # append into list\n","  img_array_list_test.append(img_array)\n","  label_list_test.append(selected_label)\n","\n","# Create data for training from the list\n","my_x_test = np.zeros((len(img_array_list_test), 299, 299, 3)) # Inception accepts (299,299,3) image\n","for i in range(len(img_array_list_test)):\n","  img_new = cv2.resize(img_array_list_test[i], dsize=(299, 299), interpolation=cv2.INTER_CUBIC)\n","  my_x_test[i] = img_new\n","# Create label for training from the list\n","label_test = np.zeros((df_all_info_test.shape[0], 1))\n","i = 0\n","for index, row in df_all_info_test.iterrows():\n","    label_test[i] = df_all_info_test[\"Topic Index\"][index]\n","    #print(i,label[i])\n","    i += 1\n","label_test = label_test.astype(int)"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jez9qzgXy8Qq","executionInfo":{"status":"ok","timestamp":1627369351569,"user_tz":420,"elapsed":178,"user":{"displayName":"Hung-Hsi Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLbZz3jls7cHNGm2KOXKxMPMSbV2b16XtapDc9NQ=s64","userId":"08494907576091059468"}}},"source":["training_images = my_x\n","training_label = label\n","val_images = my_x_test\n","val_label = label_test\n","\n","# Model building\n","# https://stackoverflow.com/questions/65594383/how-to-convert-dataset-of-images-to-tensor/65594790\n","# Self define a class which iterates over the dataset\n","class im2recipedataset(torch.utils.data.Dataset):\n","    def __init__(self, img_array, label_array):\n","      # load the dataset\n","      self.dataset = img_array\n","      self.label = label_array\n","  \n","    def __getitem__(self, idx):\n","        data = self.dataset[idx]\n","        label = self.label[idx]\n","                \n","        transform = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","        ])\n","        return transform(data), label\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","train_set = im2recipedataset(training_images,training_label)\n","valid_set = im2recipedataset(val_images,val_label)\n","\n","Data, label0 = train_set.__getitem__(0)\n","\n","train_dataloader = DataLoader(train_set, batch_size=64, shuffle=True)\n","valid_dataloader = DataLoader(valid_set, batch_size=64, shuffle=True)\n","dataloaders_dict = {\"train\":train_dataloader, \"val\": valid_dataloader}"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":100,"referenced_widgets":["770bfd7c74a1455bb2fcc70ce0ae7865","0792a6be37154b109420a93e08baaa0c","1056c12e35f4455babde95ccbe94e491","a9e0a078c7384748bc9d3ad5d9d180c5","c1ad7ec90cb346299e795a099b9dcbe0","0bec13bdb984489699a67f6c6db2b458","10b12e271fd449ae8e554fc1da9436f0","944534c0e74e4e0bafaf3cd954adc0f3"]},"id":"DZXS4SIZzTOl","executionInfo":{"status":"ok","timestamp":1627369365611,"user_tz":420,"elapsed":9171,"user":{"displayName":"Hung-Hsi Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLbZz3jls7cHNGm2KOXKxMPMSbV2b16XtapDc9NQ=s64","userId":"08494907576091059468"}},"outputId":"66b2bd70-6f58-4322-d621-004581267a6a"},"source":["# ref: https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n","def set_parameter_requires_grad(model, feature_extracting):\n","    if feature_extracting:\n","        for param in model.parameters():\n","            param.requires_grad = False\n","\n","def initialize_model(num_classes, feature_extract, use_pretrained=True):\n","    # Initialize these variables which will be set in this if statement. Each of these\n","    #   variables is model specific.\n","    model_ft = None\n","    input_size = 0\n","\n","    model_ft = models.inception_v3(pretrained=use_pretrained)\n","    set_parameter_requires_grad(model_ft, feature_extract)\n","    # Handle the auxilary net\n","    num_ftrs = model_ft.AuxLogits.fc.in_features\n","    model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n","    # Handle the primary net\n","    num_ftrs = model_ft.fc.in_features\n","    model_ft.fc = nn.Linear(num_ftrs,num_classes)\n","    input_size = 299\n","\n","    return model_ft, input_size\n","\n","\n","#  Flag for feature extracting. When False, we finetune the whole model,\n","#  when True we only update the reshaped layer params\n","feature_extract = True\n","\n","# Initialize the model for this run\n","InceptionV3, input_size = initialize_model(300, feature_extract, use_pretrained=True)\n","\n","# Print the model we just instantiated\n","#print(InceptionV3)\n","\n","# https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n","# Detect if we have a GPU available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","# Send the model to GPU\n","InceptionV3 = InceptionV3.to(device)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"770bfd7c74a1455bb2fcc70ce0ae7865","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=108949747.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mMtzWQ56zaXZ","executionInfo":{"status":"ok","timestamp":1627369366500,"user_tz":420,"elapsed":168,"user":{"displayName":"Hung-Hsi Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLbZz3jls7cHNGm2KOXKxMPMSbV2b16XtapDc9NQ=s64","userId":"08494907576091059468"}},"outputId":"b5a8940d-6c44-4576-e7d8-61ef4fd99c83"},"source":["# parameter for model hyperparameter tuning\n","learning_rate = 0.001\n","momentum_value = 0.9\n","criterion_type = nn.CrossEntropyLoss()\n","num_epochs = 200\n","\n","#=============================================\n","\n","params_to_update = InceptionV3.parameters()\n","print(\"Params to learn:\")\n","if feature_extract:\n","    params_to_update = []\n","    for name,param in InceptionV3.named_parameters():\n","        if param.requires_grad == True:\n","            params_to_update.append(param)\n","            print(\"\\t\",name)\n","else:\n","    for name,param in model_ft.named_parameters():\n","        if param.requires_grad == True:\n","            print(\"\\t\",name)\n","\n","# Observe that all parameters are being optimized\n","optimizer_ft = optim.SGD(params_to_update, lr=learning_rate , momentum=momentum_value)\n","# Setup the loss fxn\n","criterion = criterion_type"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Params to learn:\n","\t AuxLogits.fc.weight\n","\t AuxLogits.fc.bias\n","\t fc.weight\n","\t fc.bias\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MnduYUtvzabd","executionInfo":{"status":"ok","timestamp":1627369369567,"user_tz":420,"elapsed":195,"user":{"displayName":"Hung-Hsi Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLbZz3jls7cHNGm2KOXKxMPMSbV2b16XtapDc9NQ=s64","userId":"08494907576091059468"}}},"source":["def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n","    since = time.time()\n","\n","    val_acc_history = []\n","    \n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            \n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                inputs = inputs.type(torch.cuda.FloatTensor)\n","                #print(inputs.shape)\n","                labels = torch.squeeze(labels)\n","                labels = labels.to(device)\n","                #print(labels.shape)\n","                #outputs, aux_outputs = model(inputs)\n","                #print(outputs.shape)\n","                #print(aux_outputs.shape)\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    # Get model outputs and calculate loss\n","                    # Special case for inception because in training it has an auxiliary output. In train\n","                    #   mode we calculate the loss by summing the final output and the auxiliary output\n","                    #   but in testing we only consider the final output.\n","                    if is_inception and phase == 'train':\n","                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n","                        outputs, aux_outputs = model(inputs)\n","                        loss1 = criterion(outputs, labels)\n","                        loss2 = criterion(aux_outputs, labels)\n","                        loss = loss1 + 0.4*loss2\n","                    else:\n","                        outputs = model(inputs)\n","                        loss = criterion(outputs, labels)\n","\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","            if phase == 'val':\n","                val_acc_history.append(epoch_acc)\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model, val_acc_history"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1JbA_9SCzae3","executionInfo":{"status":"ok","timestamp":1627370235320,"user_tz":420,"elapsed":861620,"user":{"displayName":"Hung-Hsi Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLbZz3jls7cHNGm2KOXKxMPMSbV2b16XtapDc9NQ=s64","userId":"08494907576091059468"}},"outputId":"4b82b789-e1b2-49aa-b996-2382abb69d1d"},"source":["# Train and evaluate\n","model_ft, hist = train_model(InceptionV3, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=True)"],"execution_count":39,"outputs":[{"output_type":"stream","text":["Epoch 0/199\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"],"name":"stderr"},{"output_type":"stream","text":["train Loss: 8.0484 Acc: 0.0000\n","val Loss: 5.7177 Acc: 0.0040\n","\n","Epoch 1/199\n","----------\n","train Loss: 7.9344 Acc: 0.0100\n","val Loss: 5.7079 Acc: 0.0080\n","\n","Epoch 2/199\n","----------\n","train Loss: 7.7502 Acc: 0.0540\n","val Loss: 5.6986 Acc: 0.0060\n","\n","Epoch 3/199\n","----------\n","train Loss: 7.5835 Acc: 0.0720\n","val Loss: 5.7031 Acc: 0.0040\n","\n","Epoch 4/199\n","----------\n","train Loss: 7.3715 Acc: 0.0700\n","val Loss: 5.7198 Acc: 0.0060\n","\n","Epoch 5/199\n","----------\n","train Loss: 7.2264 Acc: 0.0760\n","val Loss: 5.7440 Acc: 0.0040\n","\n","Epoch 6/199\n","----------\n","train Loss: 7.1015 Acc: 0.0780\n","val Loss: 5.7686 Acc: 0.0060\n","\n","Epoch 7/199\n","----------\n","train Loss: 6.9862 Acc: 0.0760\n","val Loss: 5.7898 Acc: 0.0080\n","\n","Epoch 8/199\n","----------\n","train Loss: 6.8728 Acc: 0.0860\n","val Loss: 5.8056 Acc: 0.0080\n","\n","Epoch 9/199\n","----------\n","train Loss: 6.7803 Acc: 0.0880\n","val Loss: 5.8228 Acc: 0.0080\n","\n","Epoch 10/199\n","----------\n","train Loss: 6.7027 Acc: 0.1040\n","val Loss: 5.8374 Acc: 0.0080\n","\n","Epoch 11/199\n","----------\n","train Loss: 6.6129 Acc: 0.1100\n","val Loss: 5.8535 Acc: 0.0080\n","\n","Epoch 12/199\n","----------\n","train Loss: 6.5471 Acc: 0.1220\n","val Loss: 5.8649 Acc: 0.0080\n","\n","Epoch 13/199\n","----------\n","train Loss: 6.4554 Acc: 0.1280\n","val Loss: 5.8791 Acc: 0.0060\n","\n","Epoch 14/199\n","----------\n","train Loss: 6.4124 Acc: 0.1320\n","val Loss: 5.8908 Acc: 0.0080\n","\n","Epoch 15/199\n","----------\n","train Loss: 6.3416 Acc: 0.1360\n","val Loss: 5.9028 Acc: 0.0060\n","\n","Epoch 16/199\n","----------\n","train Loss: 6.2758 Acc: 0.1640\n","val Loss: 5.9119 Acc: 0.0060\n","\n","Epoch 17/199\n","----------\n","train Loss: 6.2158 Acc: 0.1620\n","val Loss: 5.9259 Acc: 0.0060\n","\n","Epoch 18/199\n","----------\n","train Loss: 6.1753 Acc: 0.1580\n","val Loss: 5.9377 Acc: 0.0080\n","\n","Epoch 19/199\n","----------\n","train Loss: 6.1170 Acc: 0.1780\n","val Loss: 5.9435 Acc: 0.0100\n","\n","Epoch 20/199\n","----------\n","train Loss: 6.0583 Acc: 0.1760\n","val Loss: 5.9518 Acc: 0.0100\n","\n","Epoch 21/199\n","----------\n","train Loss: 5.9965 Acc: 0.1920\n","val Loss: 5.9611 Acc: 0.0100\n","\n","Epoch 22/199\n","----------\n","train Loss: 5.9630 Acc: 0.1940\n","val Loss: 5.9681 Acc: 0.0100\n","\n","Epoch 23/199\n","----------\n","train Loss: 5.9119 Acc: 0.2160\n","val Loss: 5.9759 Acc: 0.0100\n","\n","Epoch 24/199\n","----------\n","train Loss: 5.8344 Acc: 0.2300\n","val Loss: 5.9830 Acc: 0.0100\n","\n","Epoch 25/199\n","----------\n","train Loss: 5.7988 Acc: 0.2140\n","val Loss: 5.9889 Acc: 0.0100\n","\n","Epoch 26/199\n","----------\n","train Loss: 5.7613 Acc: 0.2480\n","val Loss: 5.9952 Acc: 0.0100\n","\n","Epoch 27/199\n","----------\n","train Loss: 5.6887 Acc: 0.2380\n","val Loss: 6.0058 Acc: 0.0100\n","\n","Epoch 28/199\n","----------\n","train Loss: 5.6511 Acc: 0.2400\n","val Loss: 6.0098 Acc: 0.0120\n","\n","Epoch 29/199\n","----------\n","train Loss: 5.6326 Acc: 0.2520\n","val Loss: 6.0174 Acc: 0.0100\n","\n","Epoch 30/199\n","----------\n","train Loss: 5.5811 Acc: 0.2580\n","val Loss: 6.0250 Acc: 0.0100\n","\n","Epoch 31/199\n","----------\n","train Loss: 5.5196 Acc: 0.2600\n","val Loss: 6.0324 Acc: 0.0120\n","\n","Epoch 32/199\n","----------\n","train Loss: 5.4823 Acc: 0.2760\n","val Loss: 6.0361 Acc: 0.0120\n","\n","Epoch 33/199\n","----------\n","train Loss: 5.4271 Acc: 0.2900\n","val Loss: 6.0379 Acc: 0.0140\n","\n","Epoch 34/199\n","----------\n","train Loss: 5.4071 Acc: 0.2860\n","val Loss: 6.0426 Acc: 0.0120\n","\n","Epoch 35/199\n","----------\n","train Loss: 5.3587 Acc: 0.2880\n","val Loss: 6.0483 Acc: 0.0140\n","\n","Epoch 36/199\n","----------\n","train Loss: 5.3184 Acc: 0.3160\n","val Loss: 6.0512 Acc: 0.0160\n","\n","Epoch 37/199\n","----------\n","train Loss: 5.2836 Acc: 0.3000\n","val Loss: 6.0564 Acc: 0.0140\n","\n","Epoch 38/199\n","----------\n","train Loss: 5.2381 Acc: 0.3220\n","val Loss: 6.0606 Acc: 0.0120\n","\n","Epoch 39/199\n","----------\n","train Loss: 5.1783 Acc: 0.3240\n","val Loss: 6.0653 Acc: 0.0140\n","\n","Epoch 40/199\n","----------\n","train Loss: 5.1459 Acc: 0.3240\n","val Loss: 6.0726 Acc: 0.0140\n","\n","Epoch 41/199\n","----------\n","train Loss: 5.1062 Acc: 0.3520\n","val Loss: 6.0757 Acc: 0.0140\n","\n","Epoch 42/199\n","----------\n","train Loss: 5.0927 Acc: 0.3300\n","val Loss: 6.0805 Acc: 0.0140\n","\n","Epoch 43/199\n","----------\n","train Loss: 5.0331 Acc: 0.3280\n","val Loss: 6.0827 Acc: 0.0160\n","\n","Epoch 44/199\n","----------\n","train Loss: 5.0013 Acc: 0.3640\n","val Loss: 6.0913 Acc: 0.0160\n","\n","Epoch 45/199\n","----------\n","train Loss: 4.9706 Acc: 0.3560\n","val Loss: 6.0929 Acc: 0.0140\n","\n","Epoch 46/199\n","----------\n","train Loss: 4.9427 Acc: 0.3420\n","val Loss: 6.0947 Acc: 0.0140\n","\n","Epoch 47/199\n","----------\n","train Loss: 4.9058 Acc: 0.3680\n","val Loss: 6.1025 Acc: 0.0140\n","\n","Epoch 48/199\n","----------\n","train Loss: 4.8484 Acc: 0.3640\n","val Loss: 6.1038 Acc: 0.0120\n","\n","Epoch 49/199\n","----------\n","train Loss: 4.8298 Acc: 0.3700\n","val Loss: 6.1005 Acc: 0.0140\n","\n","Epoch 50/199\n","----------\n","train Loss: 4.8058 Acc: 0.3760\n","val Loss: 6.1062 Acc: 0.0140\n","\n","Epoch 51/199\n","----------\n","train Loss: 4.7573 Acc: 0.3940\n","val Loss: 6.1124 Acc: 0.0140\n","\n","Epoch 52/199\n","----------\n","train Loss: 4.7169 Acc: 0.4040\n","val Loss: 6.1174 Acc: 0.0140\n","\n","Epoch 53/199\n","----------\n","train Loss: 4.6707 Acc: 0.3900\n","val Loss: 6.1189 Acc: 0.0140\n","\n","Epoch 54/199\n","----------\n","train Loss: 4.6301 Acc: 0.3960\n","val Loss: 6.1220 Acc: 0.0140\n","\n","Epoch 55/199\n","----------\n","train Loss: 4.5991 Acc: 0.4140\n","val Loss: 6.1284 Acc: 0.0140\n","\n","Epoch 56/199\n","----------\n","train Loss: 4.5985 Acc: 0.4260\n","val Loss: 6.1317 Acc: 0.0160\n","\n","Epoch 57/199\n","----------\n","train Loss: 4.5603 Acc: 0.4320\n","val Loss: 6.1368 Acc: 0.0180\n","\n","Epoch 58/199\n","----------\n","train Loss: 4.5163 Acc: 0.4200\n","val Loss: 6.1377 Acc: 0.0180\n","\n","Epoch 59/199\n","----------\n","train Loss: 4.4898 Acc: 0.4280\n","val Loss: 6.1367 Acc: 0.0160\n","\n","Epoch 60/199\n","----------\n","train Loss: 4.4652 Acc: 0.4480\n","val Loss: 6.1368 Acc: 0.0180\n","\n","Epoch 61/199\n","----------\n","train Loss: 4.4329 Acc: 0.4580\n","val Loss: 6.1421 Acc: 0.0200\n","\n","Epoch 62/199\n","----------\n","train Loss: 4.4038 Acc: 0.4260\n","val Loss: 6.1480 Acc: 0.0200\n","\n","Epoch 63/199\n","----------\n","train Loss: 4.3358 Acc: 0.4620\n","val Loss: 6.1503 Acc: 0.0200\n","\n","Epoch 64/199\n","----------\n","train Loss: 4.3213 Acc: 0.4560\n","val Loss: 6.1518 Acc: 0.0200\n","\n","Epoch 65/199\n","----------\n","train Loss: 4.2965 Acc: 0.4660\n","val Loss: 6.1510 Acc: 0.0200\n","\n","Epoch 66/199\n","----------\n","train Loss: 4.2748 Acc: 0.4620\n","val Loss: 6.1547 Acc: 0.0200\n","\n","Epoch 67/199\n","----------\n","train Loss: 4.2232 Acc: 0.4620\n","val Loss: 6.1555 Acc: 0.0180\n","\n","Epoch 68/199\n","----------\n","train Loss: 4.2262 Acc: 0.4580\n","val Loss: 6.1598 Acc: 0.0200\n","\n","Epoch 69/199\n","----------\n","train Loss: 4.1704 Acc: 0.4740\n","val Loss: 6.1608 Acc: 0.0200\n","\n","Epoch 70/199\n","----------\n","train Loss: 4.1622 Acc: 0.4740\n","val Loss: 6.1593 Acc: 0.0200\n","\n","Epoch 71/199\n","----------\n","train Loss: 4.1421 Acc: 0.5020\n","val Loss: 6.1648 Acc: 0.0180\n","\n","Epoch 72/199\n","----------\n","train Loss: 4.0755 Acc: 0.4960\n","val Loss: 6.1650 Acc: 0.0180\n","\n","Epoch 73/199\n","----------\n","train Loss: 4.0755 Acc: 0.4900\n","val Loss: 6.1701 Acc: 0.0180\n","\n","Epoch 74/199\n","----------\n","train Loss: 4.0473 Acc: 0.5020\n","val Loss: 6.1758 Acc: 0.0200\n","\n","Epoch 75/199\n","----------\n","train Loss: 4.0063 Acc: 0.4980\n","val Loss: 6.1769 Acc: 0.0180\n","\n","Epoch 76/199\n","----------\n","train Loss: 3.9763 Acc: 0.5060\n","val Loss: 6.1799 Acc: 0.0180\n","\n","Epoch 77/199\n","----------\n","train Loss: 3.9725 Acc: 0.5100\n","val Loss: 6.1847 Acc: 0.0180\n","\n","Epoch 78/199\n","----------\n","train Loss: 3.9338 Acc: 0.5020\n","val Loss: 6.1851 Acc: 0.0180\n","\n","Epoch 79/199\n","----------\n","train Loss: 3.8920 Acc: 0.5240\n","val Loss: 6.1865 Acc: 0.0180\n","\n","Epoch 80/199\n","----------\n","train Loss: 3.8835 Acc: 0.5420\n","val Loss: 6.1837 Acc: 0.0180\n","\n","Epoch 81/199\n","----------\n","train Loss: 3.8391 Acc: 0.5240\n","val Loss: 6.1905 Acc: 0.0180\n","\n","Epoch 82/199\n","----------\n","train Loss: 3.8212 Acc: 0.5420\n","val Loss: 6.1989 Acc: 0.0180\n","\n","Epoch 83/199\n","----------\n","train Loss: 3.7948 Acc: 0.5340\n","val Loss: 6.1936 Acc: 0.0180\n","\n","Epoch 84/199\n","----------\n","train Loss: 3.7163 Acc: 0.5460\n","val Loss: 6.1964 Acc: 0.0180\n","\n","Epoch 85/199\n","----------\n","train Loss: 3.7299 Acc: 0.5500\n","val Loss: 6.1945 Acc: 0.0180\n","\n","Epoch 86/199\n","----------\n","train Loss: 3.7391 Acc: 0.5360\n","val Loss: 6.1913 Acc: 0.0180\n","\n","Epoch 87/199\n","----------\n","train Loss: 3.6683 Acc: 0.5500\n","val Loss: 6.1950 Acc: 0.0180\n","\n","Epoch 88/199\n","----------\n","train Loss: 3.6633 Acc: 0.5520\n","val Loss: 6.2032 Acc: 0.0180\n","\n","Epoch 89/199\n","----------\n","train Loss: 3.6246 Acc: 0.5620\n","val Loss: 6.2013 Acc: 0.0200\n","\n","Epoch 90/199\n","----------\n","train Loss: 3.6088 Acc: 0.5620\n","val Loss: 6.2031 Acc: 0.0180\n","\n","Epoch 91/199\n","----------\n","train Loss: 3.5461 Acc: 0.5900\n","val Loss: 6.2089 Acc: 0.0200\n","\n","Epoch 92/199\n","----------\n","train Loss: 3.5507 Acc: 0.5920\n","val Loss: 6.2115 Acc: 0.0200\n","\n","Epoch 93/199\n","----------\n","train Loss: 3.5331 Acc: 0.5720\n","val Loss: 6.2117 Acc: 0.0180\n","\n","Epoch 94/199\n","----------\n","train Loss: 3.5306 Acc: 0.5780\n","val Loss: 6.2136 Acc: 0.0180\n","\n","Epoch 95/199\n","----------\n","train Loss: 3.4526 Acc: 0.5960\n","val Loss: 6.2137 Acc: 0.0200\n","\n","Epoch 96/199\n","----------\n","train Loss: 3.5005 Acc: 0.5900\n","val Loss: 6.2141 Acc: 0.0200\n","\n","Epoch 97/199\n","----------\n","train Loss: 3.4240 Acc: 0.6060\n","val Loss: 6.2153 Acc: 0.0180\n","\n","Epoch 98/199\n","----------\n","train Loss: 3.4094 Acc: 0.6100\n","val Loss: 6.2216 Acc: 0.0200\n","\n","Epoch 99/199\n","----------\n","train Loss: 3.4024 Acc: 0.6000\n","val Loss: 6.2218 Acc: 0.0200\n","\n","Epoch 100/199\n","----------\n","train Loss: 3.3969 Acc: 0.5820\n","val Loss: 6.2171 Acc: 0.0180\n","\n","Epoch 101/199\n","----------\n","train Loss: 3.3617 Acc: 0.6100\n","val Loss: 6.2205 Acc: 0.0180\n","\n","Epoch 102/199\n","----------\n","train Loss: 3.3704 Acc: 0.6060\n","val Loss: 6.2239 Acc: 0.0180\n","\n","Epoch 103/199\n","----------\n","train Loss: 3.3013 Acc: 0.6100\n","val Loss: 6.2278 Acc: 0.0180\n","\n","Epoch 104/199\n","----------\n","train Loss: 3.3016 Acc: 0.6260\n","val Loss: 6.2262 Acc: 0.0200\n","\n","Epoch 105/199\n","----------\n","train Loss: 3.2930 Acc: 0.6280\n","val Loss: 6.2252 Acc: 0.0200\n","\n","Epoch 106/199\n","----------\n","train Loss: 3.2606 Acc: 0.6240\n","val Loss: 6.2338 Acc: 0.0180\n","\n","Epoch 107/199\n","----------\n","train Loss: 3.2285 Acc: 0.6400\n","val Loss: 6.2385 Acc: 0.0200\n","\n","Epoch 108/199\n","----------\n","train Loss: 3.2194 Acc: 0.6440\n","val Loss: 6.2363 Acc: 0.0180\n","\n","Epoch 109/199\n","----------\n","train Loss: 3.1569 Acc: 0.6300\n","val Loss: 6.2340 Acc: 0.0160\n","\n","Epoch 110/199\n","----------\n","train Loss: 3.1667 Acc: 0.6320\n","val Loss: 6.2352 Acc: 0.0180\n","\n","Epoch 111/199\n","----------\n","train Loss: 3.1298 Acc: 0.6740\n","val Loss: 6.2374 Acc: 0.0200\n","\n","Epoch 112/199\n","----------\n","train Loss: 3.1411 Acc: 0.6560\n","val Loss: 6.2406 Acc: 0.0200\n","\n","Epoch 113/199\n","----------\n","train Loss: 3.0622 Acc: 0.6800\n","val Loss: 6.2419 Acc: 0.0200\n","\n","Epoch 114/199\n","----------\n","train Loss: 3.0888 Acc: 0.6600\n","val Loss: 6.2461 Acc: 0.0200\n","\n","Epoch 115/199\n","----------\n","train Loss: 3.0566 Acc: 0.6720\n","val Loss: 6.2473 Acc: 0.0160\n","\n","Epoch 116/199\n","----------\n","train Loss: 3.0352 Acc: 0.6720\n","val Loss: 6.2469 Acc: 0.0200\n","\n","Epoch 117/199\n","----------\n","train Loss: 3.0149 Acc: 0.6580\n","val Loss: 6.2468 Acc: 0.0180\n","\n","Epoch 118/199\n","----------\n","train Loss: 2.9901 Acc: 0.6940\n","val Loss: 6.2480 Acc: 0.0180\n","\n","Epoch 119/199\n","----------\n","train Loss: 2.9704 Acc: 0.7040\n","val Loss: 6.2525 Acc: 0.0180\n","\n","Epoch 120/199\n","----------\n","train Loss: 2.9323 Acc: 0.7180\n","val Loss: 6.2567 Acc: 0.0180\n","\n","Epoch 121/199\n","----------\n","train Loss: 2.9074 Acc: 0.7040\n","val Loss: 6.2569 Acc: 0.0200\n","\n","Epoch 122/199\n","----------\n","train Loss: 2.9037 Acc: 0.7000\n","val Loss: 6.2549 Acc: 0.0180\n","\n","Epoch 123/199\n","----------\n","train Loss: 2.8644 Acc: 0.7040\n","val Loss: 6.2574 Acc: 0.0200\n","\n","Epoch 124/199\n","----------\n","train Loss: 2.8771 Acc: 0.7020\n","val Loss: 6.2601 Acc: 0.0200\n","\n","Epoch 125/199\n","----------\n","train Loss: 2.8205 Acc: 0.7240\n","val Loss: 6.2599 Acc: 0.0200\n","\n","Epoch 126/199\n","----------\n","train Loss: 2.8314 Acc: 0.6960\n","val Loss: 6.2559 Acc: 0.0200\n","\n","Epoch 127/199\n","----------\n","train Loss: 2.8238 Acc: 0.7200\n","val Loss: 6.2599 Acc: 0.0200\n","\n","Epoch 128/199\n","----------\n","train Loss: 2.7723 Acc: 0.7160\n","val Loss: 6.2623 Acc: 0.0200\n","\n","Epoch 129/199\n","----------\n","train Loss: 2.7856 Acc: 0.7200\n","val Loss: 6.2644 Acc: 0.0180\n","\n","Epoch 130/199\n","----------\n","train Loss: 2.7401 Acc: 0.7500\n","val Loss: 6.2623 Acc: 0.0200\n","\n","Epoch 131/199\n","----------\n","train Loss: 2.7750 Acc: 0.7220\n","val Loss: 6.2654 Acc: 0.0180\n","\n","Epoch 132/199\n","----------\n","train Loss: 2.7243 Acc: 0.7220\n","val Loss: 6.2648 Acc: 0.0180\n","\n","Epoch 133/199\n","----------\n","train Loss: 2.6684 Acc: 0.7500\n","val Loss: 6.2677 Acc: 0.0180\n","\n","Epoch 134/199\n","----------\n","train Loss: 2.6874 Acc: 0.7520\n","val Loss: 6.2707 Acc: 0.0180\n","\n","Epoch 135/199\n","----------\n","train Loss: 2.6562 Acc: 0.7620\n","val Loss: 6.2720 Acc: 0.0180\n","\n","Epoch 136/199\n","----------\n","train Loss: 2.6431 Acc: 0.7440\n","val Loss: 6.2717 Acc: 0.0180\n","\n","Epoch 137/199\n","----------\n","train Loss: 2.6509 Acc: 0.7620\n","val Loss: 6.2791 Acc: 0.0180\n","\n","Epoch 138/199\n","----------\n","train Loss: 2.6254 Acc: 0.7800\n","val Loss: 6.2791 Acc: 0.0180\n","\n","Epoch 139/199\n","----------\n","train Loss: 2.5899 Acc: 0.7660\n","val Loss: 6.2813 Acc: 0.0180\n","\n","Epoch 140/199\n","----------\n","train Loss: 2.5968 Acc: 0.7580\n","val Loss: 6.2813 Acc: 0.0180\n","\n","Epoch 141/199\n","----------\n","train Loss: 2.5814 Acc: 0.7460\n","val Loss: 6.2783 Acc: 0.0180\n","\n","Epoch 142/199\n","----------\n","train Loss: 2.5119 Acc: 0.7700\n","val Loss: 6.2826 Acc: 0.0180\n","\n","Epoch 143/199\n","----------\n","train Loss: 2.5001 Acc: 0.7920\n","val Loss: 6.2813 Acc: 0.0180\n","\n","Epoch 144/199\n","----------\n","train Loss: 2.5001 Acc: 0.7880\n","val Loss: 6.2857 Acc: 0.0180\n","\n","Epoch 145/199\n","----------\n","train Loss: 2.4655 Acc: 0.7960\n","val Loss: 6.2852 Acc: 0.0180\n","\n","Epoch 146/199\n","----------\n","train Loss: 2.5114 Acc: 0.7800\n","val Loss: 6.2863 Acc: 0.0180\n","\n","Epoch 147/199\n","----------\n","train Loss: 2.4791 Acc: 0.8000\n","val Loss: 6.2840 Acc: 0.0180\n","\n","Epoch 148/199\n","----------\n","train Loss: 2.4360 Acc: 0.7980\n","val Loss: 6.2856 Acc: 0.0180\n","\n","Epoch 149/199\n","----------\n","train Loss: 2.4214 Acc: 0.8080\n","val Loss: 6.2877 Acc: 0.0180\n","\n","Epoch 150/199\n","----------\n","train Loss: 2.4042 Acc: 0.8000\n","val Loss: 6.2912 Acc: 0.0180\n","\n","Epoch 151/199\n","----------\n","train Loss: 2.4127 Acc: 0.7920\n","val Loss: 6.2970 Acc: 0.0180\n","\n","Epoch 152/199\n","----------\n","train Loss: 2.3706 Acc: 0.7940\n","val Loss: 6.2983 Acc: 0.0180\n","\n","Epoch 153/199\n","----------\n","train Loss: 2.3438 Acc: 0.8220\n","val Loss: 6.3018 Acc: 0.0180\n","\n","Epoch 154/199\n","----------\n","train Loss: 2.3264 Acc: 0.7960\n","val Loss: 6.2977 Acc: 0.0180\n","\n","Epoch 155/199\n","----------\n","train Loss: 2.3163 Acc: 0.8460\n","val Loss: 6.2955 Acc: 0.0180\n","\n","Epoch 156/199\n","----------\n","train Loss: 2.3177 Acc: 0.8240\n","val Loss: 6.2994 Acc: 0.0180\n","\n","Epoch 157/199\n","----------\n","train Loss: 2.2917 Acc: 0.8360\n","val Loss: 6.3025 Acc: 0.0180\n","\n","Epoch 158/199\n","----------\n","train Loss: 2.2901 Acc: 0.8300\n","val Loss: 6.3072 Acc: 0.0180\n","\n","Epoch 159/199\n","----------\n","train Loss: 2.2813 Acc: 0.8320\n","val Loss: 6.3006 Acc: 0.0180\n","\n","Epoch 160/199\n","----------\n","train Loss: 2.2342 Acc: 0.8400\n","val Loss: 6.3048 Acc: 0.0180\n","\n","Epoch 161/199\n","----------\n","train Loss: 2.2109 Acc: 0.8580\n","val Loss: 6.3069 Acc: 0.0180\n","\n","Epoch 162/199\n","----------\n","train Loss: 2.2419 Acc: 0.8360\n","val Loss: 6.3057 Acc: 0.0180\n","\n","Epoch 163/199\n","----------\n","train Loss: 2.2024 Acc: 0.8640\n","val Loss: 6.3110 Acc: 0.0200\n","\n","Epoch 164/199\n","----------\n","train Loss: 2.2162 Acc: 0.8500\n","val Loss: 6.3130 Acc: 0.0180\n","\n","Epoch 165/199\n","----------\n","train Loss: 2.1838 Acc: 0.8360\n","val Loss: 6.3125 Acc: 0.0180\n","\n","Epoch 166/199\n","----------\n","train Loss: 2.1478 Acc: 0.8520\n","val Loss: 6.3161 Acc: 0.0180\n","\n","Epoch 167/199\n","----------\n","train Loss: 2.1492 Acc: 0.8680\n","val Loss: 6.3159 Acc: 0.0180\n","\n","Epoch 168/199\n","----------\n","train Loss: 2.1377 Acc: 0.8640\n","val Loss: 6.3161 Acc: 0.0180\n","\n","Epoch 169/199\n","----------\n","train Loss: 2.1104 Acc: 0.8640\n","val Loss: 6.3183 Acc: 0.0180\n","\n","Epoch 170/199\n","----------\n","train Loss: 2.1026 Acc: 0.8660\n","val Loss: 6.3173 Acc: 0.0180\n","\n","Epoch 171/199\n","----------\n","train Loss: 2.0796 Acc: 0.8740\n","val Loss: 6.3203 Acc: 0.0180\n","\n","Epoch 172/199\n","----------\n","train Loss: 2.0981 Acc: 0.8720\n","val Loss: 6.3196 Acc: 0.0180\n","\n","Epoch 173/199\n","----------\n","train Loss: 2.0843 Acc: 0.8740\n","val Loss: 6.3186 Acc: 0.0180\n","\n","Epoch 174/199\n","----------\n","train Loss: 2.0376 Acc: 0.8680\n","val Loss: 6.3240 Acc: 0.0180\n","\n","Epoch 175/199\n","----------\n","train Loss: 2.0133 Acc: 0.8760\n","val Loss: 6.3247 Acc: 0.0180\n","\n","Epoch 176/199\n","----------\n","train Loss: 2.0113 Acc: 0.9000\n","val Loss: 6.3222 Acc: 0.0180\n","\n","Epoch 177/199\n","----------\n","train Loss: 2.0223 Acc: 0.8700\n","val Loss: 6.3212 Acc: 0.0180\n","\n","Epoch 178/199\n","----------\n","train Loss: 1.9859 Acc: 0.8880\n","val Loss: 6.3259 Acc: 0.0180\n","\n","Epoch 179/199\n","----------\n","train Loss: 1.9851 Acc: 0.8640\n","val Loss: 6.3288 Acc: 0.0180\n","\n","Epoch 180/199\n","----------\n","train Loss: 1.9600 Acc: 0.8980\n","val Loss: 6.3253 Acc: 0.0180\n","\n","Epoch 181/199\n","----------\n","train Loss: 1.9502 Acc: 0.9200\n","val Loss: 6.3283 Acc: 0.0160\n","\n","Epoch 182/199\n","----------\n","train Loss: 1.9472 Acc: 0.9080\n","val Loss: 6.3313 Acc: 0.0180\n","\n","Epoch 183/199\n","----------\n","train Loss: 1.9252 Acc: 0.8920\n","val Loss: 6.3357 Acc: 0.0180\n","\n","Epoch 184/199\n","----------\n","train Loss: 1.9203 Acc: 0.8920\n","val Loss: 6.3295 Acc: 0.0180\n","\n","Epoch 185/199\n","----------\n","train Loss: 1.8979 Acc: 0.9160\n","val Loss: 6.3414 Acc: 0.0180\n","\n","Epoch 186/199\n","----------\n","train Loss: 1.8870 Acc: 0.8980\n","val Loss: 6.3416 Acc: 0.0180\n","\n","Epoch 187/199\n","----------\n","train Loss: 1.8923 Acc: 0.9200\n","val Loss: 6.3394 Acc: 0.0160\n","\n","Epoch 188/199\n","----------\n","train Loss: 1.8404 Acc: 0.9040\n","val Loss: 6.3401 Acc: 0.0160\n","\n","Epoch 189/199\n","----------\n","train Loss: 1.8556 Acc: 0.9160\n","val Loss: 6.3384 Acc: 0.0160\n","\n","Epoch 190/199\n","----------\n","train Loss: 1.8342 Acc: 0.9200\n","val Loss: 6.3399 Acc: 0.0160\n","\n","Epoch 191/199\n","----------\n","train Loss: 1.8159 Acc: 0.9260\n","val Loss: 6.3417 Acc: 0.0160\n","\n","Epoch 192/199\n","----------\n","train Loss: 1.8012 Acc: 0.9320\n","val Loss: 6.3516 Acc: 0.0160\n","\n","Epoch 193/199\n","----------\n","train Loss: 1.8307 Acc: 0.9200\n","val Loss: 6.3492 Acc: 0.0160\n","\n","Epoch 194/199\n","----------\n","train Loss: 1.7908 Acc: 0.9300\n","val Loss: 6.3543 Acc: 0.0180\n","\n","Epoch 195/199\n","----------\n","train Loss: 1.7610 Acc: 0.9460\n","val Loss: 6.3496 Acc: 0.0180\n","\n","Epoch 196/199\n","----------\n","train Loss: 1.7476 Acc: 0.9380\n","val Loss: 6.3522 Acc: 0.0180\n","\n","Epoch 197/199\n","----------\n","train Loss: 1.7430 Acc: 0.9480\n","val Loss: 6.3571 Acc: 0.0160\n","\n","Epoch 198/199\n","----------\n","train Loss: 1.7230 Acc: 0.9200\n","val Loss: 6.3550 Acc: 0.0160\n","\n","Epoch 199/199\n","----------\n","train Loss: 1.7467 Acc: 0.9200\n","val Loss: 6.3585 Acc: 0.0160\n","\n","Training complete in 14m 21s\n","Best val Acc: 0.020000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Q4WNIvlDQxi","executionInfo":{"status":"ok","timestamp":1627105630403,"user_tz":-480,"elapsed":306,"user":{"displayName":"Jian-Yuan Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxBRhVnXd-l8ke3uCXjs_8ibmVq4RrNyoCZxl6Rg=s64","userId":"01506185166196735520"}},"outputId":"759011f0-cbfe-4c0d-fb97-88b1a004c3d5"},"source":["loss = nn.CrossEntropyLoss()\n","input = torch.randn(3, 5, requires_grad=True)\n","print(input.shape)\n","target = torch.empty(3, dtype=torch.long).random_(5)\n","print(target.shape)\n","#output = loss(input, target)\n","#output.backward()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([3, 5])\n","torch.Size([3])\n"],"name":"stdout"}]}]}